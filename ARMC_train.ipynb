{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5261, 141) (2737, 141)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "\n",
    "#피쳐로 추출한 학습데이터 불러오기\n",
    "#with_suspicious_perm.csv : 악성코드에서 자주 사용되는 권한만 사용\n",
    "#악성앱과 정상앱 각각 불러오기\n",
    "normal_path='./extract-from-apk-master/out/0-normal/with_suspicious_perm.csv'\n",
    "malware_path='./extract-from-apk-master/out/1-malware/with_suspicious_perm.csv'\n",
    "\n",
    "#csv로 읽기\n",
    "normal_data=pd.read_csv(normal_path)\n",
    "malware_data=pd.read_csv(malware_path)\n",
    "\n",
    "#데이터 구조 확인\n",
    "#normal_data : (4000, 141)\n",
    "#malware_data : (1988,141)  2개는 dex파일 에러로 피쳐추출 실패\n",
    "print(normal_data.shape, malware_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7998, 141)\n"
     ]
    }
   ],
   "source": [
    "#악성, 정상앱 학습데이터 병합\n",
    "data=pd.concat([normal_data, malware_data])\n",
    "\n",
    "#데이터 구조 확인\n",
    "#(5998,141)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7998, 116)\n"
     ]
    }
   ],
   "source": [
    "#의미없는 피쳐 제거\n",
    "data = data.iloc[:,(data.max()!=data.min()).tolist()]\n",
    "\n",
    "#데이터 구조 확인\n",
    "#(5998, 116)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data = shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['size']=(data['size']-np.mean(data['size']))/np.std(data['size'])\n",
    "data['ep']=(data['ep']-np.mean(data['ep']))/np.std(data['ep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['label']\n",
    "X=data.iloc[:,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def do_XGBClassifier(x, y, test):\n",
    "    model = XGBClassifier(max_depth=9,\n",
    "                        nthread=4,\n",
    "                        learning_rate=0.01,\n",
    "                        objective='binary:logistic',\n",
    "                        booster='gbtree',\n",
    "                        n_estimators=2000 )\n",
    "    model.fit(x,y)\n",
    "    joblib.dump(model, 'XGB_model.pkl')\n",
    "    \n",
    "    y_pred=model.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def do_Rf(x, y, test, ESTIMATOR=200):\n",
    "    model = RandomForestClassifier(n_estimators=ESTIMATOR)\n",
    "    model.fit(x, y)\n",
    "    joblib.dump(model, 'RF_model.pkl')\n",
    "    \n",
    "    y_pred = model.predict(test)  \n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def do_SVM(x, y, test, c, g):\n",
    "    model = SVC(C=c, kernel='rbf', gamma=g)\n",
    "    model.fit(x, y)\n",
    "    joblib.dump(model, 'SVM_model.pkl')\n",
    "    \n",
    "    y_pred = model.predict(test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now=datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir=\"tf_logs\"\n",
    "logdir=\"{}/{}-DNN_150150150_dropout005_l1l2_withtest_withfull/\".format(root_logdir,now)\n",
    "\n",
    "def do_DNN(x, y, x_test, y_test):\n",
    "    #parameters\n",
    "    n_inputs=x.shape[1] #suspiciou = 135 full=229\n",
    "    n_hidden1=200\n",
    "    n_hidden2=200\n",
    "    n_outputs=2\n",
    "\n",
    "    scale1=0.001\n",
    "    scale2=0.001\n",
    "\n",
    "    dropout_rate=0.1 # == 1 - keep_prob\n",
    "\n",
    "    learning_rate=0.03\n",
    "\n",
    "    n_epochs = 1000\n",
    "    display_step=10\n",
    "    batch_size = 128\n",
    "    batch_num=x.shape[0]//batch_size\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    X=tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "    Y=tf.placeholder(tf.int64, shape=(None), name=\"Y\")\n",
    "\n",
    "    training=tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "    with tf.name_scope(\"dnn\"):\n",
    "        X_drop=tf.layers.dropout(X, dropout_rate, training=training)\n",
    "        hidden1 = tf.layers.dense(X_drop, n_hidden1, name=\"hidden1\", activation=tf.nn.relu, kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(scale1, scale2))\n",
    "        hidden1_dropp=tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "        hidden2 = tf.layers.dense(hidden1_dropp, n_hidden2, name=\"hidden2\", activation=tf.nn.relu, kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(scale1, scale2))\n",
    "        hidden2_dropp=tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "        logits = tf.layers.dense(hidden2_dropp, n_outputs, name=\"outputs\")\n",
    "    \n",
    "    with tf.name_scope(\"loss\"):\n",
    "        xentropy=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y, logits=logits)\n",
    "        loss=tf.reduce_mean(xentropy, name=\"loss\")\n",
    "        loss_summary = tf.summary.scalar('loss',loss)\n",
    "    \n",
    "    with tf.name_scope(\"train\"):\n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "    \n",
    "    with tf.name_scope(\"eval\"):\n",
    "        correct = tf.nn.in_top_k(logits, Y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        accuracy_summary = tf.summary.scalar('accuracy',accuracy)\n",
    "    \n",
    "    merged = tf.summary.merge_all()\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "    \n",
    "        file_writer = tf.summary.FileWriter(logdir,tf.get_default_graph())\n",
    "        max_acc = 0\n",
    "    \n",
    "        for epoch in range(n_epochs):\n",
    "        \n",
    "            avg_loss=0\n",
    "            X_batches = np.array_split(x, batch_num)\n",
    "            Y_batches = np.array_split(y, batch_num)\n",
    "        \n",
    "            for i in range(batch_num):\n",
    "                batch_x, batch_y = X_batches[i], Y_batches[i]\n",
    "            \n",
    "                _, ls = sess.run([training_op, loss], feed_dict={X:batch_x, Y:batch_y, training:True})  #droup out\n",
    "            \n",
    "                avg_loss += ls / batch_num\n",
    "        \n",
    "            loss_train=loss.eval(feed_dict={X:x_test, Y:y_test})\n",
    "            acc_train = accuracy.eval(feed_dict={X:x_test, Y:y_test})\n",
    "            merged_train=merged.eval(feed_dict={X:x_test, Y:y_test})\n",
    "        \n",
    "            if epoch % display_step == 0:\n",
    "                if acc_train > max_acc:\n",
    "                    max_acc=acc_train\n",
    "                \n",
    "                print(epoch, \"Avg Loss : \", avg_loss, \"Train Loss : \", loss_train, \" Train accuracy : \", acc_train, \" Max accuracy : \", max_acc)\n",
    "                file_writer.add_summary(merged_train, epoch)\n",
    "    \n",
    "        save_path=saver.save(sess, \"./mymodel_final.ckpt\")\n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, \"./mymodel_final.ckpt\")\n",
    "        \n",
    "        Z=logits.eval(feed_dict={X:x_test})\n",
    "        y_pred=np.argmax(Z, axis=1)\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def search_XGB(x, y, test):\n",
    "    parameters = {'booster':['gbtree', 'gblinear'],\n",
    "                'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              #'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05, 0.03, 0.025, 0.01], #so called `eta` value\n",
    "              'max_depth': [7, 8, 9, 10],\n",
    "              'n_estimators': [2000]} #number of trees, change it to 1000 for better results\n",
    "                    \n",
    "    scores = ['precision']#, 'recall']\n",
    "    \n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(XGBClassifier(), parameters, n_jobs=5, \n",
    "                   cv=5, \n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)\n",
    "        clf.fit(x, y)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_XGB(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Avg Loss :  0.37234565176601925 Train Loss :  0.11994456  Train accuracy :  0.9550562  Max accuracy :  0.9550562\n",
      "10 Avg Loss :  0.11288840949003183 Train Loss :  0.120894656  Train accuracy :  0.9600499  Max accuracy :  0.9600499\n",
      "20 Avg Loss :  0.10060649521515837 Train Loss :  0.11741943  Train accuracy :  0.9563046  Max accuracy :  0.9600499\n",
      "30 Avg Loss :  0.08417692318159554 Train Loss :  0.117487945  Train accuracy :  0.96629214  Max accuracy :  0.96629214\n",
      "40 Avg Loss :  0.11360372749290297 Train Loss :  0.1523194  Train accuracy :  0.9563046  Max accuracy :  0.96629214\n",
      "50 Avg Loss :  0.08690616350421417 Train Loss :  0.15195087  Train accuracy :  0.9650437  Max accuracy :  0.96629214\n",
      "60 Avg Loss :  0.0941747535086636 Train Loss :  0.1751669  Train accuracy :  0.9600499  Max accuracy :  0.96629214\n",
      "70 Avg Loss :  0.08543939738800485 Train Loss :  0.1325715  Train accuracy :  0.9600499  Max accuracy :  0.96629214\n",
      "80 Avg Loss :  0.0933099270997835 Train Loss :  0.1652669  Train accuracy :  0.9625468  Max accuracy :  0.96629214\n",
      "90 Avg Loss :  0.09768557249169268 Train Loss :  0.1995318  Train accuracy :  0.96379524  Max accuracy :  0.96629214\n",
      "100 Avg Loss :  0.07006104486728351 Train Loss :  0.18982503  Train accuracy :  0.96754056  Max accuracy :  0.96754056\n",
      "110 Avg Loss :  0.07755517510564199 Train Loss :  0.21941774  Train accuracy :  0.96754056  Max accuracy :  0.96754056\n",
      "120 Avg Loss :  0.08678024827635715 Train Loss :  0.21131407  Train accuracy :  0.9612984  Max accuracy :  0.96754056\n",
      "130 Avg Loss :  0.07515575711814951 Train Loss :  0.22386684  Train accuracy :  0.96754056  Max accuracy :  0.96754056\n",
      "140 Avg Loss :  0.09577015238547959 Train Loss :  0.36231464  Train accuracy :  0.96878904  Max accuracy :  0.96878904\n",
      "150 Avg Loss :  0.08936876860181132 Train Loss :  0.26757303  Train accuracy :  0.9612984  Max accuracy :  0.96878904\n",
      "160 Avg Loss :  0.08214209391735493 Train Loss :  0.15500447  Train accuracy :  0.9600499  Max accuracy :  0.96878904\n",
      "170 Avg Loss :  0.08487253679361725 Train Loss :  0.21510041  Train accuracy :  0.96754056  Max accuracy :  0.96878904\n",
      "180 Avg Loss :  0.11544100941890585 Train Loss :  0.4663  Train accuracy :  0.96379524  Max accuracy :  0.96878904\n",
      "190 Avg Loss :  0.07475468679331243 Train Loss :  0.18994571  Train accuracy :  0.9650437  Max accuracy :  0.96878904\n",
      "200 Avg Loss :  0.0704214643753533 Train Loss :  0.17955129  Train accuracy :  0.9625468  Max accuracy :  0.96878904\n",
      "210 Avg Loss :  0.06987298961861856 Train Loss :  0.1648456  Train accuracy :  0.9600499  Max accuracy :  0.96878904\n",
      "220 Avg Loss :  0.0876647458145661 Train Loss :  0.15997306  Train accuracy :  0.948814  Max accuracy :  0.96878904\n",
      "230 Avg Loss :  0.06580166084625358 Train Loss :  0.1884889  Train accuracy :  0.9550562  Max accuracy :  0.96878904\n",
      "240 Avg Loss :  0.13358372666074758 Train Loss :  0.34351152  Train accuracy :  0.9600499  Max accuracy :  0.96878904\n",
      "250 Avg Loss :  0.07392474569912467 Train Loss :  0.17574134  Train accuracy :  0.9612984  Max accuracy :  0.96878904\n",
      "260 Avg Loss :  0.06086806600381221 Train Loss :  0.20864537  Train accuracy :  0.96379524  Max accuracy :  0.96878904\n",
      "270 Avg Loss :  0.06506325221354409 Train Loss :  0.44851696  Train accuracy :  0.9550562  Max accuracy :  0.96878904\n",
      "280 Avg Loss :  0.084041547828487 Train Loss :  0.24587967  Train accuracy :  0.9650437  Max accuracy :  0.96878904\n",
      "290 Avg Loss :  0.05533531089479635 Train Loss :  0.25555056  Train accuracy :  0.9650437  Max accuracy :  0.96878904\n",
      "300 Avg Loss :  0.06820132596684354 Train Loss :  0.25785625  Train accuracy :  0.9588015  Max accuracy :  0.96878904\n",
      "310 Avg Loss :  0.06019034150189589 Train Loss :  0.22659422  Train accuracy :  0.9600499  Max accuracy :  0.96878904\n",
      "320 Avg Loss :  0.06248671207244375 Train Loss :  0.20705184  Train accuracy :  0.9650437  Max accuracy :  0.96878904\n",
      "330 Avg Loss :  0.055159532215579295 Train Loss :  0.36839026  Train accuracy :  0.9563046  Max accuracy :  0.96878904\n",
      "340 Avg Loss :  0.08500289168607976 Train Loss :  0.19353747  Train accuracy :  0.96878904  Max accuracy :  0.96878904\n",
      "350 Avg Loss :  0.10384672018699348 Train Loss :  0.2787336  Train accuracy :  0.9600499  Max accuracy :  0.96878904\n",
      "360 Avg Loss :  0.06531181456687463 Train Loss :  0.30385295  Train accuracy :  0.96878904  Max accuracy :  0.96878904\n",
      "370 Avg Loss :  0.07735907214893296 Train Loss :  0.29272807  Train accuracy :  0.957553  Max accuracy :  0.96878904\n",
      "380 Avg Loss :  0.0891191956720182 Train Loss :  0.41311443  Train accuracy :  0.957553  Max accuracy :  0.96878904\n",
      "390 Avg Loss :  0.06002434469493371 Train Loss :  0.191951  Train accuracy :  0.957553  Max accuracy :  0.96878904\n",
      "400 Avg Loss :  0.06425293134192803 Train Loss :  0.32889384  Train accuracy :  0.9625468  Max accuracy :  0.96878904\n",
      "410 Avg Loss :  0.0664128405707223 Train Loss :  0.22265887  Train accuracy :  0.9563046  Max accuracy :  0.96878904\n",
      "420 Avg Loss :  0.07400322753736485 Train Loss :  0.3752239  Train accuracy :  0.9563046  Max accuracy :  0.96878904\n",
      "430 Avg Loss :  0.1195508763194084 Train Loss :  0.6441727  Train accuracy :  0.948814  Max accuracy :  0.96878904\n",
      "440 Avg Loss :  0.08350965626803894 Train Loss :  0.35178623  Train accuracy :  0.9600499  Max accuracy :  0.96878904\n",
      "450 Avg Loss :  0.07248391043062187 Train Loss :  0.24061674  Train accuracy :  0.9625468  Max accuracy :  0.96878904\n",
      "460 Avg Loss :  0.05981486006307283 Train Loss :  0.18923862  Train accuracy :  0.96379524  Max accuracy :  0.96878904\n",
      "470 Avg Loss :  0.07693901378661394 Train Loss :  0.7039745  Train accuracy :  0.9588015  Max accuracy :  0.96878904\n",
      "480 Avg Loss :  0.1310677973420492 Train Loss :  0.21715099  Train accuracy :  0.9625468  Max accuracy :  0.96878904\n",
      "490 Avg Loss :  0.1066377236108695 Train Loss :  0.31972355  Train accuracy :  0.9612984  Max accuracy :  0.96878904\n",
      "500 Avg Loss :  0.07555286223734062 Train Loss :  0.35182276  Train accuracy :  0.9612984  Max accuracy :  0.96878904\n",
      "510 Avg Loss :  0.08318175909308985 Train Loss :  0.342851  Train accuracy :  0.9563046  Max accuracy :  0.96878904\n",
      "520 Avg Loss :  0.10634299204684794 Train Loss :  0.3063344  Train accuracy :  0.9600499  Max accuracy :  0.96878904\n",
      "530 Avg Loss :  0.07824972398313028 Train Loss :  0.30321768  Train accuracy :  0.957553  Max accuracy :  0.96878904\n",
      "540 Avg Loss :  0.06561107038786369 Train Loss :  0.4631011  Train accuracy :  0.96379524  Max accuracy :  0.96878904\n",
      "550 Avg Loss :  0.06725036520843526 Train Loss :  0.32570052  Train accuracy :  0.9650437  Max accuracy :  0.96878904\n",
      "560 Avg Loss :  0.07918404925814164 Train Loss :  0.4356148  Train accuracy :  0.96379524  Max accuracy :  0.96878904\n",
      "570 Avg Loss :  0.08075920153143147 Train Loss :  0.19141588  Train accuracy :  0.96629214  Max accuracy :  0.96878904\n",
      "580 Avg Loss :  0.08153394657918918 Train Loss :  0.26226133  Train accuracy :  0.9650437  Max accuracy :  0.96878904\n",
      "590 Avg Loss :  0.06785903594988797 Train Loss :  0.30074078  Train accuracy :  0.96754056  Max accuracy :  0.96878904\n",
      "600 Avg Loss :  0.07175305196350173 Train Loss :  0.4470854  Train accuracy :  0.9600499  Max accuracy :  0.96878904\n",
      "610 Avg Loss :  0.07263482347064253 Train Loss :  0.3103624  Train accuracy :  0.9650437  Max accuracy :  0.96878904\n",
      "620 Avg Loss :  0.06950051420634346 Train Loss :  0.4591882  Train accuracy :  0.96629214  Max accuracy :  0.96878904\n",
      "630 Avg Loss :  0.1159385459364525 Train Loss :  0.25865328  Train accuracy :  0.97003746  Max accuracy :  0.97003746\n",
      "640 Avg Loss :  0.08436479940012628 Train Loss :  0.23760404  Train accuracy :  0.96379524  Max accuracy :  0.97003746\n",
      "650 Avg Loss :  0.1014483011593776 Train Loss :  0.26884383  Train accuracy :  0.9650437  Max accuracy :  0.97003746\n",
      "660 Avg Loss :  0.11065882783649225 Train Loss :  0.38042298  Train accuracy :  0.9612984  Max accuracy :  0.97003746\n",
      "670 Avg Loss :  0.1635056689847261 Train Loss :  0.4324976  Train accuracy :  0.9600499  Max accuracy :  0.97003746\n",
      "680 Avg Loss :  0.07439769343805634 Train Loss :  0.42695045  Train accuracy :  0.96379524  Max accuracy :  0.97003746\n",
      "690 Avg Loss :  0.08638946630526326 Train Loss :  0.5699706  Train accuracy :  0.9650437  Max accuracy :  0.97003746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 Avg Loss :  0.07578619599475393 Train Loss :  0.6565588  Train accuracy :  0.9650437  Max accuracy :  0.97003746\n",
      "710 Avg Loss :  0.0746293791869123 Train Loss :  0.3763066  Train accuracy :  0.9625468  Max accuracy :  0.97003746\n",
      "720 Avg Loss :  0.08378797147556076 Train Loss :  0.28932917  Train accuracy :  0.9600499  Max accuracy :  0.97003746\n",
      "730 Avg Loss :  0.0774787343107164 Train Loss :  0.5440122  Train accuracy :  0.9612984  Max accuracy :  0.97003746\n",
      "740 Avg Loss :  0.10235802200622857 Train Loss :  0.7486353  Train accuracy :  0.9600499  Max accuracy :  0.97003746\n",
      "750 Avg Loss :  0.11456552332466734 Train Loss :  0.53406876  Train accuracy :  0.9600499  Max accuracy :  0.97003746\n",
      "760 Avg Loss :  0.1284062860400549 Train Loss :  0.32988247  Train accuracy :  0.9650437  Max accuracy :  0.97003746\n",
      "770 Avg Loss :  0.12817633928664565 Train Loss :  0.3457241  Train accuracy :  0.9600499  Max accuracy :  0.97003746\n",
      "780 Avg Loss :  0.07533387976166395 Train Loss :  0.34896135  Train accuracy :  0.9625468  Max accuracy :  0.97003746\n",
      "790 Avg Loss :  0.17980035901668354 Train Loss :  0.91781324  Train accuracy :  0.96379524  Max accuracy :  0.97003746\n",
      "800 Avg Loss :  0.09613442630507053 Train Loss :  0.29233283  Train accuracy :  0.9625468  Max accuracy :  0.97003746\n",
      "810 Avg Loss :  0.08089746684501216 Train Loss :  0.4133774  Train accuracy :  0.9612984  Max accuracy :  0.97003746\n",
      "820 Avg Loss :  0.07576312996180994 Train Loss :  0.46788925  Train accuracy :  0.9563046  Max accuracy :  0.97003746\n",
      "830 Avg Loss :  0.10128304581823093 Train Loss :  0.24389766  Train accuracy :  0.9612984  Max accuracy :  0.97003746\n",
      "840 Avg Loss :  0.07786345741312421 Train Loss :  0.67457724  Train accuracy :  0.96754056  Max accuracy :  0.97003746\n",
      "850 Avg Loss :  0.07118807699797407 Train Loss :  0.506196  Train accuracy :  0.9650437  Max accuracy :  0.97003746\n",
      "860 Avg Loss :  0.09694052695496273 Train Loss :  0.56450766  Train accuracy :  0.96629214  Max accuracy :  0.97003746\n",
      "870 Avg Loss :  0.08008027943183799 Train Loss :  0.5564292  Train accuracy :  0.96754056  Max accuracy :  0.97003746\n",
      "880 Avg Loss :  0.11698105789920586 Train Loss :  0.66546607  Train accuracy :  0.9612984  Max accuracy :  0.97003746\n",
      "890 Avg Loss :  0.07982374631267573 Train Loss :  0.51255566  Train accuracy :  0.9625468  Max accuracy :  0.97003746\n",
      "900 Avg Loss :  0.09661534017816721 Train Loss :  0.58600354  Train accuracy :  0.9588015  Max accuracy :  0.97003746\n",
      "910 Avg Loss :  0.08222930647233237 Train Loss :  0.59261787  Train accuracy :  0.9600499  Max accuracy :  0.97003746\n",
      "920 Avg Loss :  0.10373454983346163 Train Loss :  0.34688833  Train accuracy :  0.93882644  Max accuracy :  0.97003746\n",
      "930 Avg Loss :  0.07121527765411885 Train Loss :  0.61417764  Train accuracy :  0.96754056  Max accuracy :  0.97003746\n",
      "940 Avg Loss :  0.060952246322163534 Train Loss :  0.7780568  Train accuracy :  0.9650437  Max accuracy :  0.97003746\n",
      "950 Avg Loss :  0.07040529094436872 Train Loss :  0.756482  Train accuracy :  0.96629214  Max accuracy :  0.97003746\n",
      "960 Avg Loss :  0.12088149912389264 Train Loss :  0.532575  Train accuracy :  0.9625468  Max accuracy :  0.97003746\n",
      "970 Avg Loss :  0.09358753559977885 Train Loss :  0.6047117  Train accuracy :  0.9625468  Max accuracy :  0.97003746\n",
      "980 Avg Loss :  0.120591907695468 Train Loss :  0.26300094  Train accuracy :  0.9563046  Max accuracy :  0.97003746\n",
      "990 Avg Loss :  0.12510327647240568 Train Loss :  0.27835608  Train accuracy :  0.96379524  Max accuracy :  0.97003746\n",
      "INFO:tensorflow:Restoring parameters from ./mymodel_final.ckpt\n",
      "DNN result\n",
      "[[502  25]\n",
      " [  7 267]]\n",
      "0.9600499375780275\n",
      "XGB result\n",
      "[[512  15]\n",
      " [ 12 262]]\n",
      "0.9662921348314607\n",
      "RF result\n",
      "[[518   9]\n",
      " [ 14 260]]\n",
      "0.9712858926342073\n",
      "SVM result\n",
      "[[514  13]\n",
      " [ 11 263]]\n",
      "0.9700374531835206\n",
      "EN result\n",
      "[[509  18]\n",
      " [  8 266]]\n",
      "0.9675405742821473\n",
      "0 Avg Loss :  0.42201820627919273 Train Loss :  0.13409723  Train accuracy :  0.94125  Max accuracy :  0.94125\n",
      "10 Avg Loss :  0.11702032300776666 Train Loss :  0.10786312  Train accuracy :  0.96125  Max accuracy :  0.96125\n",
      "20 Avg Loss :  0.10649425669440199 Train Loss :  0.11658852  Train accuracy :  0.96  Max accuracy :  0.96125\n",
      "30 Avg Loss :  0.08868507578569867 Train Loss :  0.11462827  Train accuracy :  0.95625  Max accuracy :  0.96125\n",
      "40 Avg Loss :  0.09921103942074946 Train Loss :  0.09235052  Train accuracy :  0.96375  Max accuracy :  0.96375\n",
      "50 Avg Loss :  0.09188815964651961 Train Loss :  0.11540253  Train accuracy :  0.965  Max accuracy :  0.965\n",
      "60 Avg Loss :  0.08355807243580263 Train Loss :  0.1152869  Train accuracy :  0.95875  Max accuracy :  0.965\n",
      "70 Avg Loss :  0.0911099363251456 Train Loss :  0.116076015  Train accuracy :  0.96125  Max accuracy :  0.965\n",
      "80 Avg Loss :  0.07134686127704165 Train Loss :  0.20178407  Train accuracy :  0.96  Max accuracy :  0.965\n",
      "90 Avg Loss :  0.08747761886167738 Train Loss :  0.16521119  Train accuracy :  0.95625  Max accuracy :  0.965\n",
      "100 Avg Loss :  0.08009194526156144 Train Loss :  0.1616658  Train accuracy :  0.96125  Max accuracy :  0.965\n",
      "110 Avg Loss :  0.1109381250238844 Train Loss :  0.11205387  Train accuracy :  0.96375  Max accuracy :  0.965\n",
      "120 Avg Loss :  0.08670538116712122 Train Loss :  0.11872605  Train accuracy :  0.95875  Max accuracy :  0.965\n",
      "130 Avg Loss :  0.08246704985919807 Train Loss :  0.14281872  Train accuracy :  0.96625  Max accuracy :  0.96625\n",
      "140 Avg Loss :  0.09609265359384675 Train Loss :  0.1808798  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "150 Avg Loss :  0.07098191660562794 Train Loss :  0.16509868  Train accuracy :  0.95375  Max accuracy :  0.96625\n",
      "160 Avg Loss :  0.0702624109108001 Train Loss :  0.12838177  Train accuracy :  0.9575  Max accuracy :  0.96625\n",
      "170 Avg Loss :  0.08450933901726136 Train Loss :  0.19319656  Train accuracy :  0.96  Max accuracy :  0.96625\n",
      "180 Avg Loss :  0.08138547535054381 Train Loss :  0.15318273  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "190 Avg Loss :  0.08288730807336311 Train Loss :  0.17173657  Train accuracy :  0.96375  Max accuracy :  0.96625\n",
      "200 Avg Loss :  0.08475619162033708 Train Loss :  0.15472089  Train accuracy :  0.96  Max accuracy :  0.96625\n",
      "210 Avg Loss :  0.08441841738697671 Train Loss :  0.109132536  Train accuracy :  0.96375  Max accuracy :  0.96625\n",
      "220 Avg Loss :  0.0808584466243961 Train Loss :  0.13527028  Train accuracy :  0.9675  Max accuracy :  0.9675\n",
      "230 Avg Loss :  0.08620975885008066 Train Loss :  0.12165607  Train accuracy :  0.96875  Max accuracy :  0.96875\n",
      "240 Avg Loss :  0.08647529690227074 Train Loss :  0.15750104  Train accuracy :  0.96  Max accuracy :  0.96875\n",
      "250 Avg Loss :  0.07823252348628426 Train Loss :  0.16492042  Train accuracy :  0.9625  Max accuracy :  0.96875\n",
      "260 Avg Loss :  0.07715387050328511 Train Loss :  0.12733462  Train accuracy :  0.9675  Max accuracy :  0.96875\n",
      "270 Avg Loss :  0.07824984229435877 Train Loss :  0.15543613  Train accuracy :  0.97  Max accuracy :  0.97\n",
      "280 Avg Loss :  0.06655319741860564 Train Loss :  0.13949971  Train accuracy :  0.96625  Max accuracy :  0.97\n",
      "290 Avg Loss :  0.11260871439506966 Train Loss :  0.2316289  Train accuracy :  0.96375  Max accuracy :  0.97\n",
      "300 Avg Loss :  0.09893333436256009 Train Loss :  0.18611051  Train accuracy :  0.965  Max accuracy :  0.97\n",
      "310 Avg Loss :  0.10173647657835057 Train Loss :  0.118998945  Train accuracy :  0.96125  Max accuracy :  0.97\n",
      "320 Avg Loss :  0.06511098979639689 Train Loss :  0.21264435  Train accuracy :  0.96125  Max accuracy :  0.97\n",
      "330 Avg Loss :  0.08066013162689548 Train Loss :  0.16902252  Train accuracy :  0.96125  Max accuracy :  0.97\n",
      "340 Avg Loss :  0.06071744342001953 Train Loss :  0.25465804  Train accuracy :  0.9675  Max accuracy :  0.97\n",
      "350 Avg Loss :  0.07661966068137971 Train Loss :  0.11414283  Train accuracy :  0.9625  Max accuracy :  0.97\n",
      "360 Avg Loss :  0.06714942665504559 Train Loss :  0.23960772  Train accuracy :  0.96375  Max accuracy :  0.97\n",
      "370 Avg Loss :  0.07768995188442723 Train Loss :  0.17995518  Train accuracy :  0.965  Max accuracy :  0.97\n",
      "380 Avg Loss :  0.0631714518281764 Train Loss :  0.1808215  Train accuracy :  0.96375  Max accuracy :  0.97\n",
      "390 Avg Loss :  0.05277427478826471 Train Loss :  0.21246952  Train accuracy :  0.9625  Max accuracy :  0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 Avg Loss :  0.08516458385357899 Train Loss :  0.16554989  Train accuracy :  0.9675  Max accuracy :  0.97\n",
      "410 Avg Loss :  0.06527644009994607 Train Loss :  0.15303978  Train accuracy :  0.955  Max accuracy :  0.97\n",
      "420 Avg Loss :  0.08060978845294031 Train Loss :  0.15822661  Train accuracy :  0.95875  Max accuracy :  0.97\n",
      "430 Avg Loss :  0.07296754100493018 Train Loss :  0.21158098  Train accuracy :  0.96625  Max accuracy :  0.97\n",
      "440 Avg Loss :  0.14641232532449072 Train Loss :  0.20177719  Train accuracy :  0.96125  Max accuracy :  0.97\n",
      "450 Avg Loss :  0.08763511608620839 Train Loss :  0.10136342  Train accuracy :  0.96875  Max accuracy :  0.97\n",
      "460 Avg Loss :  0.06193848712635892 Train Loss :  0.12953106  Train accuracy :  0.96  Max accuracy :  0.97\n",
      "470 Avg Loss :  0.0709313474362716 Train Loss :  0.17627095  Train accuracy :  0.9575  Max accuracy :  0.97\n",
      "480 Avg Loss :  0.07779660737807194 Train Loss :  0.16023457  Train accuracy :  0.96  Max accuracy :  0.97\n",
      "490 Avg Loss :  0.07938133808784188 Train Loss :  0.30704316  Train accuracy :  0.95625  Max accuracy :  0.97\n",
      "500 Avg Loss :  0.05942265020816454 Train Loss :  0.12796552  Train accuracy :  0.96375  Max accuracy :  0.97\n",
      "510 Avg Loss :  0.056640633174018656 Train Loss :  0.32004535  Train accuracy :  0.96375  Max accuracy :  0.97\n",
      "520 Avg Loss :  0.10559754469431937 Train Loss :  0.4688151  Train accuracy :  0.96375  Max accuracy :  0.97\n",
      "530 Avg Loss :  0.07488021492359362 Train Loss :  0.28108102  Train accuracy :  0.96375  Max accuracy :  0.97\n",
      "540 Avg Loss :  0.06402900761791637 Train Loss :  0.13700886  Train accuracy :  0.9575  Max accuracy :  0.97\n",
      "550 Avg Loss :  0.08756929991899855 Train Loss :  0.20569466  Train accuracy :  0.95625  Max accuracy :  0.97\n",
      "560 Avg Loss :  0.08847471270044999 Train Loss :  0.16732228  Train accuracy :  0.955  Max accuracy :  0.97\n",
      "570 Avg Loss :  0.06719651705186282 Train Loss :  0.1170937  Train accuracy :  0.95875  Max accuracy :  0.97\n",
      "580 Avg Loss :  0.0672767283727548 Train Loss :  0.116306804  Train accuracy :  0.955  Max accuracy :  0.97\n",
      "590 Avg Loss :  0.0524566381936893 Train Loss :  0.16737759  Train accuracy :  0.955  Max accuracy :  0.97\n",
      "600 Avg Loss :  0.059597946636910974 Train Loss :  0.12561117  Train accuracy :  0.95625  Max accuracy :  0.97\n",
      "610 Avg Loss :  0.08586459586928999 Train Loss :  0.12901463  Train accuracy :  0.965  Max accuracy :  0.97\n",
      "620 Avg Loss :  0.06254504401502865 Train Loss :  0.456539  Train accuracy :  0.95625  Max accuracy :  0.97\n",
      "630 Avg Loss :  0.07773407515404479 Train Loss :  0.1510401  Train accuracy :  0.9575  Max accuracy :  0.97\n",
      "640 Avg Loss :  0.07670769697454359 Train Loss :  0.18938977  Train accuracy :  0.96125  Max accuracy :  0.97\n",
      "650 Avg Loss :  0.06970814327775901 Train Loss :  0.114704326  Train accuracy :  0.9425  Max accuracy :  0.97\n",
      "660 Avg Loss :  0.14838987758516195 Train Loss :  0.54057527  Train accuracy :  0.93375  Max accuracy :  0.97\n",
      "670 Avg Loss :  0.06238803949340114 Train Loss :  0.13452335  Train accuracy :  0.96  Max accuracy :  0.97\n",
      "680 Avg Loss :  0.06245232237103795 Train Loss :  0.21307941  Train accuracy :  0.95875  Max accuracy :  0.97\n",
      "690 Avg Loss :  0.0695945640327409 Train Loss :  0.15438971  Train accuracy :  0.94875  Max accuracy :  0.97\n",
      "700 Avg Loss :  0.05324870037813007 Train Loss :  0.18113291  Train accuracy :  0.96375  Max accuracy :  0.97\n",
      "710 Avg Loss :  0.07216039823833854 Train Loss :  0.1680529  Train accuracy :  0.9475  Max accuracy :  0.97\n",
      "720 Avg Loss :  0.0909557301617627 Train Loss :  0.16519813  Train accuracy :  0.95875  Max accuracy :  0.97\n",
      "730 Avg Loss :  0.07205526585624153 Train Loss :  0.124759406  Train accuracy :  0.9525  Max accuracy :  0.97\n",
      "740 Avg Loss :  0.09024170406961017 Train Loss :  0.16047403  Train accuracy :  0.96375  Max accuracy :  0.97\n",
      "750 Avg Loss :  0.0868236218978252 Train Loss :  0.1506632  Train accuracy :  0.9675  Max accuracy :  0.97\n",
      "760 Avg Loss :  0.06686720684436817 Train Loss :  0.09771967  Train accuracy :  0.97125  Max accuracy :  0.97125\n",
      "770 Avg Loss :  0.10748331607984647 Train Loss :  0.11469574  Train accuracy :  0.95125  Max accuracy :  0.97125\n",
      "780 Avg Loss :  0.08286330047329621 Train Loss :  0.14985372  Train accuracy :  0.97125  Max accuracy :  0.97125\n",
      "790 Avg Loss :  0.08350484259426597 Train Loss :  0.80668175  Train accuracy :  0.95375  Max accuracy :  0.97125\n",
      "800 Avg Loss :  0.0693530134657132 Train Loss :  0.13740748  Train accuracy :  0.96  Max accuracy :  0.97125\n",
      "810 Avg Loss :  0.08163734226088441 Train Loss :  0.1717353  Train accuracy :  0.95375  Max accuracy :  0.97125\n",
      "820 Avg Loss :  0.06332785661132742 Train Loss :  0.17163132  Train accuracy :  0.9625  Max accuracy :  0.97125\n",
      "830 Avg Loss :  0.07033488385578882 Train Loss :  0.2146973  Train accuracy :  0.96375  Max accuracy :  0.97125\n",
      "840 Avg Loss :  0.10508903535082936 Train Loss :  0.15973547  Train accuracy :  0.96375  Max accuracy :  0.97125\n",
      "850 Avg Loss :  0.08545557379589548 Train Loss :  0.13682058  Train accuracy :  0.96125  Max accuracy :  0.97125\n",
      "860 Avg Loss :  0.08841876461104094 Train Loss :  0.16624081  Train accuracy :  0.955  Max accuracy :  0.97125\n",
      "870 Avg Loss :  0.08485027708645376 Train Loss :  0.113067046  Train accuracy :  0.96  Max accuracy :  0.97125\n",
      "880 Avg Loss :  0.0989592954782503 Train Loss :  0.21097682  Train accuracy :  0.965  Max accuracy :  0.97125\n",
      "890 Avg Loss :  0.0899886978856687 Train Loss :  0.20842376  Train accuracy :  0.9575  Max accuracy :  0.97125\n",
      "900 Avg Loss :  0.06805823693451073 Train Loss :  0.14331813  Train accuracy :  0.94875  Max accuracy :  0.97125\n",
      "910 Avg Loss :  0.22300209697069864 Train Loss :  0.487978  Train accuracy :  0.85375  Max accuracy :  0.97125\n",
      "920 Avg Loss :  0.08222558159780287 Train Loss :  0.3057059  Train accuracy :  0.96  Max accuracy :  0.97125\n",
      "930 Avg Loss :  0.09307328145951033 Train Loss :  0.10254168  Train accuracy :  0.95625  Max accuracy :  0.97125\n",
      "940 Avg Loss :  0.07490303255950233 Train Loss :  0.12538558  Train accuracy :  0.95375  Max accuracy :  0.97125\n",
      "950 Avg Loss :  0.06450921940683786 Train Loss :  0.12268871  Train accuracy :  0.9625  Max accuracy :  0.97125\n",
      "960 Avg Loss :  0.07330319549821848 Train Loss :  0.15876646  Train accuracy :  0.9475  Max accuracy :  0.97125\n",
      "970 Avg Loss :  0.06437224485645338 Train Loss :  0.17176647  Train accuracy :  0.9625  Max accuracy :  0.97125\n",
      "980 Avg Loss :  0.10193703486584126 Train Loss :  0.19056164  Train accuracy :  0.96375  Max accuracy :  0.97125\n",
      "990 Avg Loss :  0.08968202217615075 Train Loss :  0.13254261  Train accuracy :  0.96375  Max accuracy :  0.97125\n",
      "INFO:tensorflow:Restoring parameters from ./mymodel_final.ckpt\n",
      "DNN result\n",
      "[[509  17]\n",
      " [ 11 263]]\n",
      "0.965\n",
      "XGB result\n",
      "[[519   7]\n",
      " [ 16 258]]\n",
      "0.97125\n",
      "RF result\n",
      "[[518   8]\n",
      " [ 22 252]]\n",
      "0.9625\n",
      "SVM result\n",
      "[[519   7]\n",
      " [ 17 257]]\n",
      "0.97\n",
      "EN result\n",
      "[[519   7]\n",
      " [ 13 261]]\n",
      "0.975\n",
      "0 Avg Loss :  0.4179815237543413 Train Loss :  0.1608615  Train accuracy :  0.94625  Max accuracy :  0.94625\n",
      "10 Avg Loss :  0.11103334291172882 Train Loss :  0.11357084  Train accuracy :  0.965  Max accuracy :  0.965\n",
      "20 Avg Loss :  0.09517232900751492 Train Loss :  0.13814546  Train accuracy :  0.95875  Max accuracy :  0.965\n",
      "30 Avg Loss :  0.08790429259118225 Train Loss :  0.12613235  Train accuracy :  0.965  Max accuracy :  0.965\n",
      "40 Avg Loss :  0.1162999937576907 Train Loss :  0.1276073  Train accuracy :  0.95625  Max accuracy :  0.965\n",
      "50 Avg Loss :  0.0975989212415049 Train Loss :  0.19165088  Train accuracy :  0.95375  Max accuracy :  0.965\n",
      "60 Avg Loss :  0.07683364245375351 Train Loss :  0.14285555  Train accuracy :  0.965  Max accuracy :  0.965\n",
      "70 Avg Loss :  0.09177449541831653 Train Loss :  0.165924  Train accuracy :  0.96625  Max accuracy :  0.96625\n",
      "80 Avg Loss :  0.08512148217830276 Train Loss :  0.17128353  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "90 Avg Loss :  0.08164379176949818 Train Loss :  0.20652336  Train accuracy :  0.95625  Max accuracy :  0.96625\n",
      "100 Avg Loss :  0.07744061953521202 Train Loss :  0.16556808  Train accuracy :  0.965  Max accuracy :  0.96625\n",
      "110 Avg Loss :  0.06774687700505769 Train Loss :  0.1723399  Train accuracy :  0.96  Max accuracy :  0.96625\n",
      "120 Avg Loss :  0.08653647502485132 Train Loss :  0.16445379  Train accuracy :  0.9675  Max accuracy :  0.9675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 Avg Loss :  0.06142139218614568 Train Loss :  0.1968148  Train accuracy :  0.955  Max accuracy :  0.9675\n",
      "140 Avg Loss :  0.07444200318838867 Train Loss :  0.14585684  Train accuracy :  0.96125  Max accuracy :  0.9675\n",
      "150 Avg Loss :  0.07977253507955799 Train Loss :  0.19083  Train accuracy :  0.9625  Max accuracy :  0.9675\n",
      "160 Avg Loss :  0.07874555539871964 Train Loss :  0.17638978  Train accuracy :  0.95875  Max accuracy :  0.9675\n",
      "170 Avg Loss :  0.07176652846724858 Train Loss :  0.18691106  Train accuracy :  0.96125  Max accuracy :  0.9675\n",
      "180 Avg Loss :  0.07736733771993647 Train Loss :  0.2997717  Train accuracy :  0.94875  Max accuracy :  0.9675\n",
      "190 Avg Loss :  0.06662260607949323 Train Loss :  0.32134154  Train accuracy :  0.96  Max accuracy :  0.9675\n",
      "200 Avg Loss :  0.07474824616552464 Train Loss :  0.15826204  Train accuracy :  0.96375  Max accuracy :  0.9675\n",
      "210 Avg Loss :  0.07582789237078812 Train Loss :  0.2191401  Train accuracy :  0.95  Max accuracy :  0.9675\n",
      "220 Avg Loss :  0.0821471083742965 Train Loss :  0.17962788  Train accuracy :  0.965  Max accuracy :  0.9675\n",
      "230 Avg Loss :  0.07761218678206203 Train Loss :  0.16253293  Train accuracy :  0.95875  Max accuracy :  0.9675\n",
      "240 Avg Loss :  0.0649542925280652 Train Loss :  0.1578782  Train accuracy :  0.96125  Max accuracy :  0.9675\n",
      "250 Avg Loss :  0.0813737308074321 Train Loss :  0.15047345  Train accuracy :  0.96  Max accuracy :  0.9675\n",
      "260 Avg Loss :  0.07209645843665513 Train Loss :  0.17113023  Train accuracy :  0.96125  Max accuracy :  0.9675\n",
      "270 Avg Loss :  0.07416208148268719 Train Loss :  0.14924318  Train accuracy :  0.95875  Max accuracy :  0.9675\n",
      "280 Avg Loss :  0.06790733919478956 Train Loss :  0.224701  Train accuracy :  0.95875  Max accuracy :  0.9675\n",
      "290 Avg Loss :  0.06267946048839285 Train Loss :  0.17030966  Train accuracy :  0.965  Max accuracy :  0.9675\n",
      "300 Avg Loss :  0.06053895583110196 Train Loss :  0.19954892  Train accuracy :  0.96625  Max accuracy :  0.9675\n",
      "310 Avg Loss :  0.08817441099589424 Train Loss :  0.17402571  Train accuracy :  0.95625  Max accuracy :  0.9675\n",
      "320 Avg Loss :  0.07135844935796092 Train Loss :  0.20163316  Train accuracy :  0.9625  Max accuracy :  0.9675\n",
      "330 Avg Loss :  0.07495819068779903 Train Loss :  0.13714826  Train accuracy :  0.96625  Max accuracy :  0.9675\n",
      "340 Avg Loss :  0.05667518787751238 Train Loss :  0.1816898  Train accuracy :  0.96375  Max accuracy :  0.9675\n",
      "350 Avg Loss :  0.06495788217788295 Train Loss :  0.21340114  Train accuracy :  0.965  Max accuracy :  0.9675\n",
      "360 Avg Loss :  0.06308244487237452 Train Loss :  0.2760783  Train accuracy :  0.96375  Max accuracy :  0.9675\n",
      "370 Avg Loss :  0.05206108590521451 Train Loss :  0.19604048  Train accuracy :  0.96375  Max accuracy :  0.9675\n",
      "380 Avg Loss :  0.08247967107620621 Train Loss :  0.20891239  Train accuracy :  0.95125  Max accuracy :  0.9675\n",
      "390 Avg Loss :  0.0933972861052358 Train Loss :  0.19624615  Train accuracy :  0.9475  Max accuracy :  0.9675\n",
      "400 Avg Loss :  0.07122534247381346 Train Loss :  0.41006574  Train accuracy :  0.95  Max accuracy :  0.9675\n",
      "410 Avg Loss :  0.06862371671013534 Train Loss :  0.20930405  Train accuracy :  0.9575  Max accuracy :  0.9675\n",
      "420 Avg Loss :  0.07965195293737842 Train Loss :  0.2770797  Train accuracy :  0.96375  Max accuracy :  0.9675\n",
      "430 Avg Loss :  0.08008632463003906 Train Loss :  0.14822407  Train accuracy :  0.955  Max accuracy :  0.9675\n",
      "440 Avg Loss :  0.06274691104356732 Train Loss :  0.13858491  Train accuracy :  0.95  Max accuracy :  0.9675\n",
      "450 Avg Loss :  0.06027725029603712 Train Loss :  0.16810995  Train accuracy :  0.96375  Max accuracy :  0.9675\n",
      "460 Avg Loss :  0.06841484061442316 Train Loss :  0.24120685  Train accuracy :  0.95875  Max accuracy :  0.9675\n",
      "470 Avg Loss :  0.07016178596365664 Train Loss :  0.2819823  Train accuracy :  0.95875  Max accuracy :  0.9675\n",
      "480 Avg Loss :  0.06363802211957852 Train Loss :  0.26002294  Train accuracy :  0.96375  Max accuracy :  0.9675\n",
      "490 Avg Loss :  0.08416248112916945 Train Loss :  0.27327356  Train accuracy :  0.96  Max accuracy :  0.9675\n",
      "500 Avg Loss :  0.0843086439916598 Train Loss :  0.4237278  Train accuracy :  0.95375  Max accuracy :  0.9675\n",
      "510 Avg Loss :  0.1108821364718356 Train Loss :  0.23539634  Train accuracy :  0.9575  Max accuracy :  0.9675\n",
      "520 Avg Loss :  0.06679621684764114 Train Loss :  0.20883226  Train accuracy :  0.95625  Max accuracy :  0.9675\n",
      "530 Avg Loss :  0.09010358613782694 Train Loss :  0.2360777  Train accuracy :  0.95375  Max accuracy :  0.9675\n",
      "540 Avg Loss :  0.08372018000643168 Train Loss :  0.17977342  Train accuracy :  0.96375  Max accuracy :  0.9675\n",
      "550 Avg Loss :  0.09121254016645253 Train Loss :  0.2525873  Train accuracy :  0.96375  Max accuracy :  0.9675\n",
      "560 Avg Loss :  0.07033724527406907 Train Loss :  0.2571833  Train accuracy :  0.96125  Max accuracy :  0.9675\n",
      "570 Avg Loss :  0.0763947110223983 Train Loss :  0.23745804  Train accuracy :  0.95125  Max accuracy :  0.9675\n",
      "580 Avg Loss :  0.5102456044405701 Train Loss :  0.14991517  Train accuracy :  0.9575  Max accuracy :  0.9675\n",
      "590 Avg Loss :  0.08094975219241209 Train Loss :  0.15888189  Train accuracy :  0.95875  Max accuracy :  0.9675\n",
      "600 Avg Loss :  0.07071049948821638 Train Loss :  0.39449465  Train accuracy :  0.9525  Max accuracy :  0.9675\n",
      "610 Avg Loss :  0.08042315004526507 Train Loss :  0.38725662  Train accuracy :  0.95625  Max accuracy :  0.9675\n",
      "620 Avg Loss :  0.06946698386621265 Train Loss :  0.19185592  Train accuracy :  0.96  Max accuracy :  0.9675\n",
      "630 Avg Loss :  0.07963935290795884 Train Loss :  0.22168003  Train accuracy :  0.9625  Max accuracy :  0.9675\n",
      "640 Avg Loss :  0.1043253995012492 Train Loss :  0.17491247  Train accuracy :  0.9575  Max accuracy :  0.9675\n",
      "650 Avg Loss :  0.07013306868196068 Train Loss :  0.21185017  Train accuracy :  0.9575  Max accuracy :  0.9675\n",
      "660 Avg Loss :  0.06557551678270102 Train Loss :  0.3412957  Train accuracy :  0.95875  Max accuracy :  0.9675\n",
      "670 Avg Loss :  0.08455502411483654 Train Loss :  0.26910344  Train accuracy :  0.96375  Max accuracy :  0.9675\n",
      "680 Avg Loss :  0.05360932130965271 Train Loss :  0.32635716  Train accuracy :  0.9375  Max accuracy :  0.9675\n",
      "690 Avg Loss :  0.1434005600001131 Train Loss :  0.2888196  Train accuracy :  0.955  Max accuracy :  0.9675\n",
      "700 Avg Loss :  0.19534801478896824 Train Loss :  0.48708588  Train accuracy :  0.95625  Max accuracy :  0.9675\n",
      "710 Avg Loss :  0.11939768370107881 Train Loss :  0.3121946  Train accuracy :  0.95625  Max accuracy :  0.9675\n",
      "720 Avg Loss :  0.0671350283747805 Train Loss :  0.22951017  Train accuracy :  0.95625  Max accuracy :  0.9675\n",
      "730 Avg Loss :  0.06896374649867149 Train Loss :  0.4129335  Train accuracy :  0.96  Max accuracy :  0.9675\n",
      "740 Avg Loss :  0.06747702414369477 Train Loss :  0.29322964  Train accuracy :  0.955  Max accuracy :  0.9675\n",
      "750 Avg Loss :  0.06024449263765874 Train Loss :  0.2790049  Train accuracy :  0.96375  Max accuracy :  0.9675\n",
      "760 Avg Loss :  0.058215473662130535 Train Loss :  0.3336901  Train accuracy :  0.94625  Max accuracy :  0.9675\n",
      "770 Avg Loss :  0.05317882988934541 Train Loss :  0.2685522  Train accuracy :  0.9575  Max accuracy :  0.9675\n",
      "780 Avg Loss :  0.06950747027128402 Train Loss :  0.30229193  Train accuracy :  0.95875  Max accuracy :  0.9675\n",
      "790 Avg Loss :  0.05759796689796661 Train Loss :  0.29440725  Train accuracy :  0.96  Max accuracy :  0.9675\n",
      "800 Avg Loss :  0.07018012614987257 Train Loss :  0.33259818  Train accuracy :  0.945  Max accuracy :  0.9675\n",
      "810 Avg Loss :  0.07365784479770808 Train Loss :  0.29925403  Train accuracy :  0.95125  Max accuracy :  0.9675\n",
      "820 Avg Loss :  0.1358968395673271 Train Loss :  0.24602023  Train accuracy :  0.9375  Max accuracy :  0.9675\n",
      "830 Avg Loss :  0.11719456128776073 Train Loss :  0.3144205  Train accuracy :  0.95875  Max accuracy :  0.9675\n",
      "840 Avg Loss :  0.06637018380154455 Train Loss :  0.19249366  Train accuracy :  0.95125  Max accuracy :  0.9675\n",
      "850 Avg Loss :  0.06137170078831591 Train Loss :  0.23430577  Train accuracy :  0.95875  Max accuracy :  0.9675\n",
      "860 Avg Loss :  0.21824692035027385 Train Loss :  0.38508856  Train accuracy :  0.96  Max accuracy :  0.9675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870 Avg Loss :  0.0810759477317333 Train Loss :  0.41713676  Train accuracy :  0.95  Max accuracy :  0.9675\n",
      "880 Avg Loss :  0.08338744615736816 Train Loss :  0.47126022  Train accuracy :  0.95  Max accuracy :  0.9675\n",
      "890 Avg Loss :  0.07565188880211539 Train Loss :  0.56461656  Train accuracy :  0.96  Max accuracy :  0.9675\n",
      "900 Avg Loss :  0.06492722821089308 Train Loss :  0.4634818  Train accuracy :  0.94  Max accuracy :  0.9675\n",
      "910 Avg Loss :  0.088408131667945 Train Loss :  0.44976863  Train accuracy :  0.96  Max accuracy :  0.9675\n",
      "920 Avg Loss :  0.11354664513575179 Train Loss :  0.5252592  Train accuracy :  0.95875  Max accuracy :  0.9675\n",
      "930 Avg Loss :  0.09403526743075678 Train Loss :  0.8415416  Train accuracy :  0.9425  Max accuracy :  0.9675\n",
      "940 Avg Loss :  0.09105307848325798 Train Loss :  0.40575957  Train accuracy :  0.95625  Max accuracy :  0.9675\n",
      "950 Avg Loss :  0.10187101430658785 Train Loss :  0.44558823  Train accuracy :  0.95625  Max accuracy :  0.9675\n",
      "960 Avg Loss :  0.060463267311986015 Train Loss :  0.42019078  Train accuracy :  0.95875  Max accuracy :  0.9675\n",
      "970 Avg Loss :  0.06386113090307584 Train Loss :  0.7086874  Train accuracy :  0.95375  Max accuracy :  0.9675\n",
      "980 Avg Loss :  0.062343061452598436 Train Loss :  1.007772  Train accuracy :  0.96  Max accuracy :  0.9675\n",
      "990 Avg Loss :  0.05462119553703817 Train Loss :  0.42987588  Train accuracy :  0.9575  Max accuracy :  0.9675\n",
      "INFO:tensorflow:Restoring parameters from ./mymodel_final.ckpt\n",
      "DNN result\n",
      "[[504  22]\n",
      " [ 12 262]]\n",
      "0.9575\n",
      "XGB result\n",
      "[[509  17]\n",
      " [ 15 259]]\n",
      "0.96\n",
      "RF result\n",
      "[[515  11]\n",
      " [ 14 260]]\n",
      "0.96875\n",
      "SVM result\n",
      "[[511  15]\n",
      " [ 17 257]]\n",
      "0.96\n",
      "EN result\n",
      "[[509  17]\n",
      " [  8 266]]\n",
      "0.96875\n",
      "0 Avg Loss :  0.32516632575009535 Train Loss :  0.13668695  Train accuracy :  0.9425  Max accuracy :  0.9425\n",
      "10 Avg Loss :  0.10921283864549225 Train Loss :  0.13365814  Train accuracy :  0.95375  Max accuracy :  0.95375\n",
      "20 Avg Loss :  0.09969290528845573 Train Loss :  0.116975695  Train accuracy :  0.96  Max accuracy :  0.96\n",
      "30 Avg Loss :  0.10485951096883844 Train Loss :  0.12763882  Train accuracy :  0.9575  Max accuracy :  0.96\n",
      "40 Avg Loss :  0.08263463347351976 Train Loss :  0.1256311  Train accuracy :  0.96  Max accuracy :  0.96\n",
      "50 Avg Loss :  0.11106428720190058 Train Loss :  0.13479888  Train accuracy :  0.95625  Max accuracy :  0.96\n",
      "60 Avg Loss :  0.08368320363972866 Train Loss :  0.15736406  Train accuracy :  0.96125  Max accuracy :  0.96125\n",
      "70 Avg Loss :  0.0895892780806337 Train Loss :  0.15352875  Train accuracy :  0.9575  Max accuracy :  0.96125\n",
      "80 Avg Loss :  0.08395003904921138 Train Loss :  0.19886208  Train accuracy :  0.9425  Max accuracy :  0.96125\n",
      "90 Avg Loss :  0.07513601838478019 Train Loss :  0.14158274  Train accuracy :  0.9625  Max accuracy :  0.9625\n",
      "100 Avg Loss :  0.0844194627300437 Train Loss :  0.1394186  Train accuracy :  0.96  Max accuracy :  0.9625\n",
      "110 Avg Loss :  0.076954121102712 Train Loss :  0.14246422  Train accuracy :  0.96  Max accuracy :  0.9625\n",
      "120 Avg Loss :  0.08219512422303003 Train Loss :  0.12929285  Train accuracy :  0.96375  Max accuracy :  0.96375\n",
      "130 Avg Loss :  0.07492216081092398 Train Loss :  0.19787033  Train accuracy :  0.95  Max accuracy :  0.96375\n",
      "140 Avg Loss :  0.07806592123649483 Train Loss :  0.11957951  Train accuracy :  0.9625  Max accuracy :  0.96375\n",
      "150 Avg Loss :  0.08209102873557378 Train Loss :  0.18454495  Train accuracy :  0.965  Max accuracy :  0.965\n",
      "160 Avg Loss :  0.09997570671008102 Train Loss :  0.12510002  Train accuracy :  0.9575  Max accuracy :  0.965\n",
      "170 Avg Loss :  0.08555072303196151 Train Loss :  0.15307197  Train accuracy :  0.96625  Max accuracy :  0.96625\n",
      "180 Avg Loss :  0.06588667088986506 Train Loss :  0.17461388  Train accuracy :  0.955  Max accuracy :  0.96625\n",
      "190 Avg Loss :  0.07843001615921304 Train Loss :  0.22757405  Train accuracy :  0.96375  Max accuracy :  0.96625\n",
      "200 Avg Loss :  0.07584430994133332 Train Loss :  0.15218444  Train accuracy :  0.9575  Max accuracy :  0.96625\n",
      "210 Avg Loss :  0.07290823202181075 Train Loss :  0.19316775  Train accuracy :  0.95625  Max accuracy :  0.96625\n",
      "220 Avg Loss :  0.06538914157343761 Train Loss :  0.15582842  Train accuracy :  0.96125  Max accuracy :  0.96625\n",
      "230 Avg Loss :  0.07769168504247709 Train Loss :  0.17760856  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "240 Avg Loss :  0.07230090729093981 Train Loss :  0.19767874  Train accuracy :  0.965  Max accuracy :  0.96625\n",
      "250 Avg Loss :  0.06931638950482011 Train Loss :  0.15594961  Train accuracy :  0.9625  Max accuracy :  0.96625\n",
      "260 Avg Loss :  0.07933687355502378 Train Loss :  0.2235205  Train accuracy :  0.9625  Max accuracy :  0.96625\n",
      "270 Avg Loss :  0.10755928234928953 Train Loss :  0.49530038  Train accuracy :  0.9625  Max accuracy :  0.96625\n",
      "280 Avg Loss :  0.10413135302120022 Train Loss :  0.13272472  Train accuracy :  0.9575  Max accuracy :  0.96625\n",
      "290 Avg Loss :  0.0913211103595261 Train Loss :  0.3751737  Train accuracy :  0.9625  Max accuracy :  0.96625\n",
      "300 Avg Loss :  0.07832393582378117 Train Loss :  0.21552855  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "310 Avg Loss :  0.08703770102666958 Train Loss :  0.2155262  Train accuracy :  0.96125  Max accuracy :  0.96625\n",
      "320 Avg Loss :  0.07412537172370191 Train Loss :  0.20269565  Train accuracy :  0.94625  Max accuracy :  0.96625\n",
      "330 Avg Loss :  0.08474839901152462 Train Loss :  0.19455193  Train accuracy :  0.9425  Max accuracy :  0.96625\n",
      "340 Avg Loss :  0.07999139648330002 Train Loss :  0.1318358  Train accuracy :  0.95625  Max accuracy :  0.96625\n",
      "350 Avg Loss :  0.09409770938301724 Train Loss :  0.16092436  Train accuracy :  0.95  Max accuracy :  0.96625\n",
      "360 Avg Loss :  0.07540059565300389 Train Loss :  0.17039883  Train accuracy :  0.955  Max accuracy :  0.96625\n",
      "370 Avg Loss :  0.05911778944677541 Train Loss :  0.18851069  Train accuracy :  0.95625  Max accuracy :  0.96625\n",
      "380 Avg Loss :  0.08699872417907624 Train Loss :  0.15589911  Train accuracy :  0.9575  Max accuracy :  0.96625\n",
      "390 Avg Loss :  0.06780922033690982 Train Loss :  0.22919682  Train accuracy :  0.95625  Max accuracy :  0.96625\n",
      "400 Avg Loss :  0.07415131477838649 Train Loss :  0.22275442  Train accuracy :  0.965  Max accuracy :  0.96625\n",
      "410 Avg Loss :  0.06738603597373834 Train Loss :  0.1843042  Train accuracy :  0.9575  Max accuracy :  0.96625\n",
      "420 Avg Loss :  0.07459732201615614 Train Loss :  0.21219078  Train accuracy :  0.955  Max accuracy :  0.96625\n",
      "430 Avg Loss :  0.07700957597366402 Train Loss :  0.690812  Train accuracy :  0.95375  Max accuracy :  0.96625\n",
      "440 Avg Loss :  0.09495777606831066 Train Loss :  0.2278513  Train accuracy :  0.955  Max accuracy :  0.96625\n",
      "450 Avg Loss :  0.11582070489280992 Train Loss :  0.3182433  Train accuracy :  0.955  Max accuracy :  0.96625\n",
      "460 Avg Loss :  0.08651232607995293 Train Loss :  0.26344398  Train accuracy :  0.96375  Max accuracy :  0.96625\n",
      "470 Avg Loss :  0.10050041082182103 Train Loss :  0.31049356  Train accuracy :  0.9425  Max accuracy :  0.96625\n",
      "480 Avg Loss :  0.07861888016174948 Train Loss :  0.34162468  Train accuracy :  0.95  Max accuracy :  0.96625\n",
      "490 Avg Loss :  0.08464639793549267 Train Loss :  0.1897762  Train accuracy :  0.95125  Max accuracy :  0.96625\n",
      "500 Avg Loss :  0.08185196305359048 Train Loss :  0.701268  Train accuracy :  0.95375  Max accuracy :  0.96625\n",
      "510 Avg Loss :  0.05928183137439194 Train Loss :  0.5603474  Train accuracy :  0.96125  Max accuracy :  0.96625\n",
      "520 Avg Loss :  0.057286085219987286 Train Loss :  0.61770177  Train accuracy :  0.9475  Max accuracy :  0.96625\n",
      "530 Avg Loss :  0.05385942406220629 Train Loss :  0.30416453  Train accuracy :  0.9575  Max accuracy :  0.96625\n",
      "540 Avg Loss :  0.059527885925490416 Train Loss :  0.38766238  Train accuracy :  0.96  Max accuracy :  0.96625\n",
      "550 Avg Loss :  0.07322708161414736 Train Loss :  0.23536915  Train accuracy :  0.96125  Max accuracy :  0.96625\n",
      "560 Avg Loss :  0.09824295052593311 Train Loss :  0.37377244  Train accuracy :  0.96125  Max accuracy :  0.96625\n",
      "570 Avg Loss :  0.061325381077559915 Train Loss :  0.7781089  Train accuracy :  0.9525  Max accuracy :  0.96625\n",
      "580 Avg Loss :  0.08106073713861404 Train Loss :  0.22789505  Train accuracy :  0.9575  Max accuracy :  0.96625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590 Avg Loss :  0.1048208585873778 Train Loss :  0.32600665  Train accuracy :  0.95125  Max accuracy :  0.96625\n",
      "600 Avg Loss :  0.06677535315975547 Train Loss :  1.3155656  Train accuracy :  0.95125  Max accuracy :  0.96625\n",
      "610 Avg Loss :  0.05768939408673242 Train Loss :  0.24928714  Train accuracy :  0.96375  Max accuracy :  0.96625\n",
      "620 Avg Loss :  0.09195048601499624 Train Loss :  0.4123456  Train accuracy :  0.955  Max accuracy :  0.96625\n",
      "630 Avg Loss :  0.07422633632086217 Train Loss :  0.3734021  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "640 Avg Loss :  0.07332039987003165 Train Loss :  0.3656802  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "650 Avg Loss :  0.06002568433593425 Train Loss :  0.21763565  Train accuracy :  0.965  Max accuracy :  0.96625\n",
      "660 Avg Loss :  0.08269869492921443 Train Loss :  0.22369298  Train accuracy :  0.95625  Max accuracy :  0.96625\n",
      "670 Avg Loss :  0.08393897395581006 Train Loss :  0.17846222  Train accuracy :  0.96125  Max accuracy :  0.96625\n",
      "680 Avg Loss :  0.08256016329063903 Train Loss :  0.16256008  Train accuracy :  0.94375  Max accuracy :  0.96625\n",
      "690 Avg Loss :  0.10569970509303468 Train Loss :  2.2115524  Train accuracy :  0.9625  Max accuracy :  0.96625\n",
      "700 Avg Loss :  0.08387257122168586 Train Loss :  0.19909607  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "710 Avg Loss :  0.07239918444039564 Train Loss :  0.17054638  Train accuracy :  0.95625  Max accuracy :  0.96625\n",
      "720 Avg Loss :  0.10686701238487979 Train Loss :  0.17919682  Train accuracy :  0.96  Max accuracy :  0.96625\n",
      "730 Avg Loss :  0.06092730568655367 Train Loss :  0.24957067  Train accuracy :  0.95375  Max accuracy :  0.96625\n",
      "740 Avg Loss :  0.07785521657206118 Train Loss :  0.34721714  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "750 Avg Loss :  0.07897613447026482 Train Loss :  0.24965195  Train accuracy :  0.94875  Max accuracy :  0.96625\n",
      "760 Avg Loss :  0.06852153863292187 Train Loss :  0.16334824  Train accuracy :  0.96125  Max accuracy :  0.96625\n",
      "770 Avg Loss :  0.06420062472378568 Train Loss :  0.704956  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "780 Avg Loss :  0.10323525208514182 Train Loss :  2.2765205  Train accuracy :  0.95375  Max accuracy :  0.96625\n",
      "790 Avg Loss :  0.07015210413374005 Train Loss :  0.47568625  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "800 Avg Loss :  0.14408781392765904 Train Loss :  0.34436426  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "810 Avg Loss :  0.09551135620235333 Train Loss :  0.57475233  Train accuracy :  0.9625  Max accuracy :  0.96625\n",
      "820 Avg Loss :  0.07745441757807772 Train Loss :  0.7001782  Train accuracy :  0.9575  Max accuracy :  0.96625\n",
      "830 Avg Loss :  0.07828866078385283 Train Loss :  0.5191522  Train accuracy :  0.9575  Max accuracy :  0.96625\n",
      "840 Avg Loss :  0.08761971141211684 Train Loss :  0.22677216  Train accuracy :  0.955  Max accuracy :  0.96625\n",
      "850 Avg Loss :  0.10113777950339552 Train Loss :  0.3100289  Train accuracy :  0.95625  Max accuracy :  0.96625\n",
      "860 Avg Loss :  0.0919406547743295 Train Loss :  0.2540189  Train accuracy :  0.96  Max accuracy :  0.96625\n",
      "870 Avg Loss :  0.08285653953706582 Train Loss :  0.15884171  Train accuracy :  0.96125  Max accuracy :  0.96625\n",
      "880 Avg Loss :  0.07735462347045542 Train Loss :  0.15625969  Train accuracy :  0.96125  Max accuracy :  0.96625\n",
      "890 Avg Loss :  0.06137957121245564 Train Loss :  0.30323613  Train accuracy :  0.9625  Max accuracy :  0.96625\n",
      "900 Avg Loss :  0.08054177629362265 Train Loss :  0.33346602  Train accuracy :  0.9475  Max accuracy :  0.96625\n",
      "910 Avg Loss :  0.06716510656821939 Train Loss :  1.5482141  Train accuracy :  0.95375  Max accuracy :  0.96625\n",
      "920 Avg Loss :  0.11111425245845954 Train Loss :  0.535395  Train accuracy :  0.96375  Max accuracy :  0.96625\n",
      "930 Avg Loss :  0.16125214425846937 Train Loss :  3.3093872  Train accuracy :  0.9575  Max accuracy :  0.96625\n",
      "940 Avg Loss :  0.11587110793750201 Train Loss :  0.88658315  Train accuracy :  0.955  Max accuracy :  0.96625\n",
      "950 Avg Loss :  0.0933253332041204 Train Loss :  0.62117505  Train accuracy :  0.9575  Max accuracy :  0.96625\n",
      "960 Avg Loss :  0.085137805402545 Train Loss :  0.21114682  Train accuracy :  0.95  Max accuracy :  0.96625\n",
      "970 Avg Loss :  0.07112588806610022 Train Loss :  0.36613682  Train accuracy :  0.955  Max accuracy :  0.96625\n",
      "980 Avg Loss :  0.07310005323961379 Train Loss :  0.4416543  Train accuracy :  0.95125  Max accuracy :  0.96625\n",
      "990 Avg Loss :  0.07914517247783284 Train Loss :  0.6954147  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "INFO:tensorflow:Restoring parameters from ./mymodel_final.ckpt\n",
      "DNN result\n",
      "[[499  27]\n",
      " [  6 268]]\n",
      "0.95875\n",
      "XGB result\n",
      "[[510  16]\n",
      " [ 14 260]]\n",
      "0.9625\n",
      "RF result\n",
      "[[513  13]\n",
      " [ 13 261]]\n",
      "0.9675\n",
      "SVM result\n",
      "[[511  15]\n",
      " [ 18 256]]\n",
      "0.95875\n",
      "EN result\n",
      "[[506  20]\n",
      " [ 11 263]]\n",
      "0.96125\n",
      "0 Avg Loss :  0.3935980960460644 Train Loss :  0.16569395  Train accuracy :  0.94625  Max accuracy :  0.94625\n",
      "10 Avg Loss :  0.10858216143346261 Train Loss :  0.17655739  Train accuracy :  0.94125  Max accuracy :  0.94625\n",
      "20 Avg Loss :  0.10502730629273824 Train Loss :  0.17544724  Train accuracy :  0.9525  Max accuracy :  0.9525\n",
      "30 Avg Loss :  0.08507064440553741 Train Loss :  0.22203833  Train accuracy :  0.955  Max accuracy :  0.955\n",
      "40 Avg Loss :  0.08256351302510924 Train Loss :  0.22859634  Train accuracy :  0.94125  Max accuracy :  0.955\n",
      "50 Avg Loss :  0.07951298685345265 Train Loss :  0.26900598  Train accuracy :  0.95375  Max accuracy :  0.955\n",
      "60 Avg Loss :  0.08459217959482754 Train Loss :  0.23713453  Train accuracy :  0.9475  Max accuracy :  0.955\n",
      "70 Avg Loss :  0.08491844926694674 Train Loss :  0.2408644  Train accuracy :  0.95125  Max accuracy :  0.955\n",
      "80 Avg Loss :  0.08934503038679914 Train Loss :  0.25693023  Train accuracy :  0.945  Max accuracy :  0.955\n",
      "90 Avg Loss :  0.07781246504081148 Train Loss :  0.3377221  Train accuracy :  0.95375  Max accuracy :  0.955\n",
      "100 Avg Loss :  0.0816877253819257 Train Loss :  0.36609924  Train accuracy :  0.9525  Max accuracy :  0.955\n",
      "110 Avg Loss :  0.09242976689711216 Train Loss :  0.44106275  Train accuracy :  0.94375  Max accuracy :  0.955\n",
      "120 Avg Loss :  0.07149144155638558 Train Loss :  0.30925682  Train accuracy :  0.94  Max accuracy :  0.955\n",
      "130 Avg Loss :  0.08042489501115463 Train Loss :  0.43703315  Train accuracy :  0.9525  Max accuracy :  0.955\n",
      "140 Avg Loss :  0.06734317664190063 Train Loss :  0.31920922  Train accuracy :  0.95375  Max accuracy :  0.955\n",
      "150 Avg Loss :  0.08255454259259361 Train Loss :  0.34905374  Train accuracy :  0.945  Max accuracy :  0.955\n",
      "160 Avg Loss :  0.0840217157466603 Train Loss :  0.57422376  Train accuracy :  0.94875  Max accuracy :  0.955\n",
      "170 Avg Loss :  0.06857889262028039 Train Loss :  0.34788552  Train accuracy :  0.94875  Max accuracy :  0.955\n",
      "180 Avg Loss :  0.07689831900643185 Train Loss :  0.30786735  Train accuracy :  0.955  Max accuracy :  0.955\n",
      "190 Avg Loss :  0.08793837670236825 Train Loss :  0.36125386  Train accuracy :  0.95625  Max accuracy :  0.95625\n",
      "200 Avg Loss :  0.09368830420342941 Train Loss :  0.33844024  Train accuracy :  0.94625  Max accuracy :  0.95625\n",
      "210 Avg Loss :  0.06286322129225093 Train Loss :  0.3709958  Train accuracy :  0.9525  Max accuracy :  0.95625\n",
      "220 Avg Loss :  0.056730087014979544 Train Loss :  0.41482362  Train accuracy :  0.95  Max accuracy :  0.95625\n",
      "230 Avg Loss :  0.0798785537813923 Train Loss :  0.45755073  Train accuracy :  0.94375  Max accuracy :  0.95625\n",
      "240 Avg Loss :  0.090951152811093 Train Loss :  0.5826445  Train accuracy :  0.945  Max accuracy :  0.95625\n",
      "250 Avg Loss :  0.06784479915430504 Train Loss :  0.4614631  Train accuracy :  0.94  Max accuracy :  0.95625\n",
      "260 Avg Loss :  0.0728695427533239 Train Loss :  0.49968553  Train accuracy :  0.9425  Max accuracy :  0.95625\n",
      "270 Avg Loss :  0.09505585610999595 Train Loss :  0.33631814  Train accuracy :  0.93875  Max accuracy :  0.95625\n",
      "280 Avg Loss :  0.1106752727978996 Train Loss :  0.5205996  Train accuracy :  0.93875  Max accuracy :  0.95625\n",
      "290 Avg Loss :  0.07770340577034013 Train Loss :  0.6751131  Train accuracy :  0.945  Max accuracy :  0.95625\n",
      "300 Avg Loss :  0.09154245816171169 Train Loss :  0.42817506  Train accuracy :  0.93  Max accuracy :  0.95625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310 Avg Loss :  0.07754005591518114 Train Loss :  0.41981754  Train accuracy :  0.9425  Max accuracy :  0.95625\n",
      "320 Avg Loss :  0.06972968965835336 Train Loss :  0.45237365  Train accuracy :  0.9475  Max accuracy :  0.95625\n",
      "330 Avg Loss :  0.06149497431969004 Train Loss :  1.0675783  Train accuracy :  0.93625  Max accuracy :  0.95625\n",
      "340 Avg Loss :  0.075716284003907 Train Loss :  0.75474626  Train accuracy :  0.9425  Max accuracy :  0.95625\n",
      "350 Avg Loss :  0.07090173144492189 Train Loss :  0.619221  Train accuracy :  0.94125  Max accuracy :  0.95625\n",
      "360 Avg Loss :  0.06463548121973871 Train Loss :  0.77399886  Train accuracy :  0.9425  Max accuracy :  0.95625\n",
      "370 Avg Loss :  0.13370271201711145 Train Loss :  0.5293352  Train accuracy :  0.9475  Max accuracy :  0.95625\n",
      "380 Avg Loss :  0.07081926414476977 Train Loss :  0.7193482  Train accuracy :  0.95  Max accuracy :  0.95625\n",
      "390 Avg Loss :  0.0816365270210164 Train Loss :  1.1830151  Train accuracy :  0.9325  Max accuracy :  0.95625\n",
      "400 Avg Loss :  0.07032143159969044 Train Loss :  0.6428527  Train accuracy :  0.94625  Max accuracy :  0.95625\n",
      "410 Avg Loss :  0.08384143927001525 Train Loss :  0.72270477  Train accuracy :  0.9325  Max accuracy :  0.95625\n",
      "420 Avg Loss :  0.08266441859970133 Train Loss :  0.71812004  Train accuracy :  0.93375  Max accuracy :  0.95625\n",
      "430 Avg Loss :  0.06795602125514826 Train Loss :  0.6303773  Train accuracy :  0.93875  Max accuracy :  0.95625\n",
      "440 Avg Loss :  0.07721838275236743 Train Loss :  0.8047615  Train accuracy :  0.94  Max accuracy :  0.95625\n",
      "450 Avg Loss :  0.0660610185337386 Train Loss :  0.4222882  Train accuracy :  0.9475  Max accuracy :  0.95625\n",
      "460 Avg Loss :  0.07663361636722194 Train Loss :  0.6183484  Train accuracy :  0.94125  Max accuracy :  0.95625\n",
      "470 Avg Loss :  0.09880056539883038 Train Loss :  0.63391984  Train accuracy :  0.9325  Max accuracy :  0.95625\n",
      "480 Avg Loss :  0.07146404440780836 Train Loss :  0.52767867  Train accuracy :  0.93125  Max accuracy :  0.95625\n",
      "490 Avg Loss :  0.09345872873174296 Train Loss :  0.59691626  Train accuracy :  0.93625  Max accuracy :  0.95625\n",
      "500 Avg Loss :  0.05838560938302959 Train Loss :  0.5849884  Train accuracy :  0.94125  Max accuracy :  0.95625\n",
      "510 Avg Loss :  0.07063710862504582 Train Loss :  1.3404137  Train accuracy :  0.94125  Max accuracy :  0.95625\n",
      "520 Avg Loss :  0.07180892353478288 Train Loss :  0.7738898  Train accuracy :  0.9375  Max accuracy :  0.95625\n",
      "530 Avg Loss :  0.08956093650444276 Train Loss :  1.1409135  Train accuracy :  0.94875  Max accuracy :  0.95625\n",
      "540 Avg Loss :  0.08382900538189067 Train Loss :  0.6683586  Train accuracy :  0.935  Max accuracy :  0.95625\n",
      "550 Avg Loss :  0.06852012175867067 Train Loss :  0.8157384  Train accuracy :  0.9375  Max accuracy :  0.95625\n",
      "560 Avg Loss :  0.06963208149785974 Train Loss :  0.9996208  Train accuracy :  0.935  Max accuracy :  0.95625\n",
      "570 Avg Loss :  0.07154925260692835 Train Loss :  0.98945206  Train accuracy :  0.945  Max accuracy :  0.95625\n",
      "580 Avg Loss :  0.10554444716711127 Train Loss :  1.6089892  Train accuracy :  0.9275  Max accuracy :  0.95625\n",
      "590 Avg Loss :  0.0649135371869696 Train Loss :  1.4191699  Train accuracy :  0.92875  Max accuracy :  0.95625\n",
      "600 Avg Loss :  0.08073703691895515 Train Loss :  0.9988001  Train accuracy :  0.94125  Max accuracy :  0.95625\n",
      "610 Avg Loss :  0.1305223828115101 Train Loss :  1.429244  Train accuracy :  0.9275  Max accuracy :  0.95625\n",
      "620 Avg Loss :  0.07247859422516612 Train Loss :  0.6806932  Train accuracy :  0.9375  Max accuracy :  0.95625\n",
      "630 Avg Loss :  0.06997619369732481 Train Loss :  0.6950895  Train accuracy :  0.94  Max accuracy :  0.95625\n",
      "640 Avg Loss :  0.06062849251819508 Train Loss :  0.5052482  Train accuracy :  0.95  Max accuracy :  0.95625\n",
      "650 Avg Loss :  0.0810620463453233 Train Loss :  0.9454961  Train accuracy :  0.9375  Max accuracy :  0.95625\n",
      "660 Avg Loss :  0.06209251071725573 Train Loss :  0.7736418  Train accuracy :  0.94625  Max accuracy :  0.95625\n",
      "670 Avg Loss :  0.08135218703786709 Train Loss :  0.83397126  Train accuracy :  0.945  Max accuracy :  0.95625\n",
      "680 Avg Loss :  0.08088654369514968 Train Loss :  2.3643675  Train accuracy :  0.935  Max accuracy :  0.95625\n",
      "690 Avg Loss :  0.12048110648590542 Train Loss :  0.7418921  Train accuracy :  0.93375  Max accuracy :  0.95625\n",
      "700 Avg Loss :  0.07014932985683636 Train Loss :  0.92072046  Train accuracy :  0.935  Max accuracy :  0.95625\n",
      "710 Avg Loss :  0.0655529476436121 Train Loss :  1.47056  Train accuracy :  0.94125  Max accuracy :  0.95625\n",
      "720 Avg Loss :  0.12799858621188576 Train Loss :  2.8321028  Train accuracy :  0.945  Max accuracy :  0.95625\n",
      "730 Avg Loss :  0.08858433891353862 Train Loss :  1.3130231  Train accuracy :  0.95  Max accuracy :  0.95625\n",
      "740 Avg Loss :  0.08404705114662646 Train Loss :  3.138324  Train accuracy :  0.94625  Max accuracy :  0.95625\n",
      "750 Avg Loss :  0.0983775569059487 Train Loss :  1.7034415  Train accuracy :  0.925  Max accuracy :  0.95625\n",
      "760 Avg Loss :  0.12050849219251958 Train Loss :  2.3035617  Train accuracy :  0.92875  Max accuracy :  0.95625\n",
      "770 Avg Loss :  0.0816384996952755 Train Loss :  2.1085703  Train accuracy :  0.935  Max accuracy :  0.95625\n",
      "780 Avg Loss :  0.18195267474012713 Train Loss :  1.6436682  Train accuracy :  0.935  Max accuracy :  0.95625\n",
      "790 Avg Loss :  0.14066872113783443 Train Loss :  3.3331902  Train accuracy :  0.93625  Max accuracy :  0.95625\n",
      "800 Avg Loss :  0.09516349833990849 Train Loss :  2.793472  Train accuracy :  0.93125  Max accuracy :  0.95625\n",
      "810 Avg Loss :  0.08748635633050333 Train Loss :  1.7165331  Train accuracy :  0.94125  Max accuracy :  0.95625\n",
      "820 Avg Loss :  0.06640496675390752 Train Loss :  2.2996042  Train accuracy :  0.94375  Max accuracy :  0.95625\n",
      "830 Avg Loss :  0.1414273679256439 Train Loss :  1.3782473  Train accuracy :  0.9325  Max accuracy :  0.95625\n",
      "840 Avg Loss :  0.0778558584196227 Train Loss :  3.7844372  Train accuracy :  0.9425  Max accuracy :  0.95625\n",
      "850 Avg Loss :  0.1154145426782114 Train Loss :  1.8894917  Train accuracy :  0.93875  Max accuracy :  0.95625\n",
      "860 Avg Loss :  0.1925994309131056 Train Loss :  3.5102313  Train accuracy :  0.87125  Max accuracy :  0.95625\n",
      "870 Avg Loss :  0.1572158306038805 Train Loss :  0.9924173  Train accuracy :  0.91375  Max accuracy :  0.95625\n",
      "880 Avg Loss :  0.16370505132778954 Train Loss :  1.5724046  Train accuracy :  0.945  Max accuracy :  0.95625\n",
      "890 Avg Loss :  0.07154791918583213 Train Loss :  2.7795746  Train accuracy :  0.93375  Max accuracy :  0.95625\n",
      "900 Avg Loss :  0.10544345867154853 Train Loss :  1.0290855  Train accuracy :  0.9275  Max accuracy :  0.95625\n",
      "910 Avg Loss :  0.0691715670483453 Train Loss :  0.6683306  Train accuracy :  0.9325  Max accuracy :  0.95625\n",
      "920 Avg Loss :  0.09801152194891723 Train Loss :  2.1210978  Train accuracy :  0.93375  Max accuracy :  0.95625\n",
      "930 Avg Loss :  0.07535373472741673 Train Loss :  3.337191  Train accuracy :  0.93375  Max accuracy :  0.95625\n",
      "940 Avg Loss :  0.06644990637765398 Train Loss :  2.8620868  Train accuracy :  0.92875  Max accuracy :  0.95625\n",
      "950 Avg Loss :  0.07041751980848078 Train Loss :  2.4564505  Train accuracy :  0.93375  Max accuracy :  0.95625\n",
      "960 Avg Loss :  0.08615997400400895 Train Loss :  1.6930327  Train accuracy :  0.94  Max accuracy :  0.95625\n",
      "970 Avg Loss :  0.057261392515751415 Train Loss :  2.7593665  Train accuracy :  0.94125  Max accuracy :  0.95625\n",
      "980 Avg Loss :  0.11518829738322114 Train Loss :  4.183668  Train accuracy :  0.9325  Max accuracy :  0.95625\n",
      "990 Avg Loss :  0.07312453227184179 Train Loss :  1.8000777  Train accuracy :  0.93875  Max accuracy :  0.95625\n",
      "INFO:tensorflow:Restoring parameters from ./mymodel_final.ckpt\n",
      "DNN result\n",
      "[[471  55]\n",
      " [ 12 262]]\n",
      "0.91625\n",
      "XGB result\n",
      "[[511  15]\n",
      " [ 17 257]]\n",
      "0.96\n",
      "RF result\n",
      "[[508  18]\n",
      " [ 21 253]]\n",
      "0.95125\n",
      "SVM result\n",
      "[[513  13]\n",
      " [ 21 253]]\n",
      "0.9575\n",
      "EN result\n",
      "[[504  22]\n",
      " [ 14 260]]\n",
      "0.955\n",
      "0 Avg Loss :  0.4330343661297647 Train Loss :  0.145604  Train accuracy :  0.94875  Max accuracy :  0.94875\n",
      "10 Avg Loss :  0.1236103137822023 Train Loss :  0.16619398  Train accuracy :  0.94375  Max accuracy :  0.94875\n",
      "20 Avg Loss :  0.10615497378499376 Train Loss :  0.1835748  Train accuracy :  0.94875  Max accuracy :  0.94875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Avg Loss :  0.09823506438572495 Train Loss :  0.14738163  Train accuracy :  0.95875  Max accuracy :  0.95875\n",
      "40 Avg Loss :  0.0958410956331396 Train Loss :  0.21996681  Train accuracy :  0.95625  Max accuracy :  0.95875\n",
      "50 Avg Loss :  0.08441059001987533 Train Loss :  0.1555736  Train accuracy :  0.95625  Max accuracy :  0.95875\n",
      "60 Avg Loss :  0.09326939893487309 Train Loss :  0.15136153  Train accuracy :  0.9625  Max accuracy :  0.9625\n",
      "70 Avg Loss :  0.10434580401384405 Train Loss :  0.14560854  Train accuracy :  0.95375  Max accuracy :  0.9625\n",
      "80 Avg Loss :  0.08827935495147748 Train Loss :  0.19383356  Train accuracy :  0.96125  Max accuracy :  0.9625\n",
      "90 Avg Loss :  0.09274335780979268 Train Loss :  0.21826115  Train accuracy :  0.95125  Max accuracy :  0.9625\n",
      "100 Avg Loss :  0.10880502981932037 Train Loss :  0.18393017  Train accuracy :  0.95625  Max accuracy :  0.9625\n",
      "110 Avg Loss :  0.08439267998827356 Train Loss :  0.14055355  Train accuracy :  0.96  Max accuracy :  0.9625\n",
      "120 Avg Loss :  0.08903140960527318 Train Loss :  0.22808617  Train accuracy :  0.96  Max accuracy :  0.9625\n",
      "130 Avg Loss :  0.09152506544653857 Train Loss :  0.17922336  Train accuracy :  0.955  Max accuracy :  0.9625\n",
      "140 Avg Loss :  0.10377818959698612 Train Loss :  0.44708622  Train accuracy :  0.9525  Max accuracy :  0.9625\n",
      "150 Avg Loss :  0.08286271201047514 Train Loss :  0.20300904  Train accuracy :  0.96125  Max accuracy :  0.9625\n",
      "160 Avg Loss :  0.07688848172048372 Train Loss :  0.24496351  Train accuracy :  0.96  Max accuracy :  0.9625\n",
      "170 Avg Loss :  0.07915950842600847 Train Loss :  0.21707922  Train accuracy :  0.955  Max accuracy :  0.9625\n",
      "180 Avg Loss :  0.0863265451542767 Train Loss :  0.22504811  Train accuracy :  0.9625  Max accuracy :  0.9625\n",
      "190 Avg Loss :  0.0982815768968846 Train Loss :  0.17193224  Train accuracy :  0.96  Max accuracy :  0.9625\n",
      "200 Avg Loss :  0.08916949384313608 Train Loss :  0.28333408  Train accuracy :  0.95875  Max accuracy :  0.9625\n",
      "210 Avg Loss :  0.09066057268397082 Train Loss :  0.26611763  Train accuracy :  0.95875  Max accuracy :  0.9625\n",
      "220 Avg Loss :  0.07998696634812016 Train Loss :  0.29855937  Train accuracy :  0.9575  Max accuracy :  0.9625\n",
      "230 Avg Loss :  0.09337955711609015 Train Loss :  0.5141798  Train accuracy :  0.9575  Max accuracy :  0.9625\n",
      "240 Avg Loss :  0.08607033101309622 Train Loss :  0.3881543  Train accuracy :  0.96  Max accuracy :  0.9625\n",
      "250 Avg Loss :  0.08344028820283711 Train Loss :  0.2124277  Train accuracy :  0.9625  Max accuracy :  0.9625\n",
      "260 Avg Loss :  0.07626180299225131 Train Loss :  0.3196012  Train accuracy :  0.95375  Max accuracy :  0.9625\n",
      "270 Avg Loss :  0.07870114844159358 Train Loss :  0.19907524  Train accuracy :  0.95625  Max accuracy :  0.9625\n",
      "280 Avg Loss :  0.08816784264386765 Train Loss :  0.28797466  Train accuracy :  0.96375  Max accuracy :  0.96375\n",
      "290 Avg Loss :  0.07545133912935852 Train Loss :  0.3618862  Train accuracy :  0.9575  Max accuracy :  0.96375\n",
      "300 Avg Loss :  0.06934185553940812 Train Loss :  0.36812535  Train accuracy :  0.9625  Max accuracy :  0.96375\n",
      "310 Avg Loss :  0.08752192659968777 Train Loss :  0.41983253  Train accuracy :  0.955  Max accuracy :  0.96375\n",
      "320 Avg Loss :  0.08465772607762899 Train Loss :  0.3511203  Train accuracy :  0.95625  Max accuracy :  0.96375\n",
      "330 Avg Loss :  0.09263598004222982 Train Loss :  0.4914494  Train accuracy :  0.9625  Max accuracy :  0.96375\n",
      "340 Avg Loss :  0.09374300245794337 Train Loss :  0.28963634  Train accuracy :  0.95875  Max accuracy :  0.96375\n",
      "350 Avg Loss :  0.08874861185904594 Train Loss :  0.44070163  Train accuracy :  0.9625  Max accuracy :  0.96375\n",
      "360 Avg Loss :  0.09713565674610436 Train Loss :  0.25699976  Train accuracy :  0.9625  Max accuracy :  0.96375\n",
      "370 Avg Loss :  0.15194327883156283 Train Loss :  0.29973292  Train accuracy :  0.9575  Max accuracy :  0.96375\n",
      "380 Avg Loss :  0.0724746125384367 Train Loss :  0.25439185  Train accuracy :  0.965  Max accuracy :  0.965\n",
      "390 Avg Loss :  0.07346928615256082 Train Loss :  0.377082  Train accuracy :  0.9575  Max accuracy :  0.965\n",
      "400 Avg Loss :  0.08473552653699049 Train Loss :  0.307872  Train accuracy :  0.95875  Max accuracy :  0.965\n",
      "410 Avg Loss :  0.06703657402457404 Train Loss :  0.29150006  Train accuracy :  0.9575  Max accuracy :  0.965\n",
      "420 Avg Loss :  0.08052965330093034 Train Loss :  0.31858054  Train accuracy :  0.96  Max accuracy :  0.965\n",
      "430 Avg Loss :  0.08059666352346537 Train Loss :  0.49106652  Train accuracy :  0.9525  Max accuracy :  0.965\n",
      "440 Avg Loss :  0.07149086892604829 Train Loss :  0.58510375  Train accuracy :  0.9575  Max accuracy :  0.965\n",
      "450 Avg Loss :  0.0709023700162236 Train Loss :  0.25838003  Train accuracy :  0.96625  Max accuracy :  0.96625\n",
      "460 Avg Loss :  0.06226062797941268 Train Loss :  0.3914728  Train accuracy :  0.9625  Max accuracy :  0.96625\n",
      "470 Avg Loss :  0.08055827952921389 Train Loss :  0.3469523  Train accuracy :  0.96  Max accuracy :  0.96625\n",
      "480 Avg Loss :  0.10838542935172363 Train Loss :  0.3020866  Train accuracy :  0.9625  Max accuracy :  0.96625\n",
      "490 Avg Loss :  0.06296600610949098 Train Loss :  0.37567565  Train accuracy :  0.965  Max accuracy :  0.96625\n",
      "500 Avg Loss :  0.15487860415929128 Train Loss :  0.50873405  Train accuracy :  0.95  Max accuracy :  0.96625\n",
      "510 Avg Loss :  0.07046106238184231 Train Loss :  0.41437274  Train accuracy :  0.96625  Max accuracy :  0.96625\n",
      "520 Avg Loss :  0.11964039052171366 Train Loss :  0.5321386  Train accuracy :  0.96375  Max accuracy :  0.96625\n",
      "530 Avg Loss :  0.09207436216196846 Train Loss :  0.24477196  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "540 Avg Loss :  0.08254802283564848 Train Loss :  0.28954074  Train accuracy :  0.9525  Max accuracy :  0.96625\n",
      "550 Avg Loss :  0.08534420615926916 Train Loss :  0.46646157  Train accuracy :  0.955  Max accuracy :  0.96625\n",
      "560 Avg Loss :  0.1094364335294813 Train Loss :  0.91951925  Train accuracy :  0.955  Max accuracy :  0.96625\n",
      "570 Avg Loss :  0.08992101538128083 Train Loss :  0.8108265  Train accuracy :  0.96125  Max accuracy :  0.96625\n",
      "580 Avg Loss :  0.08867807396953657 Train Loss :  0.35130265  Train accuracy :  0.95625  Max accuracy :  0.96625\n",
      "590 Avg Loss :  0.06377900973893702 Train Loss :  0.24737309  Train accuracy :  0.9575  Max accuracy :  0.96625\n",
      "600 Avg Loss :  0.07558622261110161 Train Loss :  0.46517566  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "610 Avg Loss :  0.07578642879213607 Train Loss :  0.22986543  Train accuracy :  0.96  Max accuracy :  0.96625\n",
      "620 Avg Loss :  0.11131603157679949 Train Loss :  0.91437095  Train accuracy :  0.9525  Max accuracy :  0.96625\n",
      "630 Avg Loss :  0.07844639027358169 Train Loss :  1.1544822  Train accuracy :  0.96  Max accuracy :  0.96625\n",
      "640 Avg Loss :  0.06972876305891466 Train Loss :  0.1929299  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "650 Avg Loss :  0.08714614402768868 Train Loss :  0.7880421  Train accuracy :  0.955  Max accuracy :  0.96625\n",
      "660 Avg Loss :  0.10734941654040346 Train Loss :  0.30672282  Train accuracy :  0.9525  Max accuracy :  0.96625\n",
      "670 Avg Loss :  0.12693461493056804 Train Loss :  1.457084  Train accuracy :  0.9575  Max accuracy :  0.96625\n",
      "680 Avg Loss :  0.08359071938320997 Train Loss :  1.8043649  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "690 Avg Loss :  0.11694910277479462 Train Loss :  0.5793457  Train accuracy :  0.9625  Max accuracy :  0.96625\n",
      "700 Avg Loss :  0.08599285711534323 Train Loss :  0.5782774  Train accuracy :  0.96125  Max accuracy :  0.96625\n",
      "710 Avg Loss :  0.06355032740559961 Train Loss :  0.43909177  Train accuracy :  0.955  Max accuracy :  0.96625\n",
      "720 Avg Loss :  0.0771291604531663 Train Loss :  0.5425761  Train accuracy :  0.95375  Max accuracy :  0.96625\n",
      "730 Avg Loss :  0.08106792480352201 Train Loss :  0.9398062  Train accuracy :  0.95375  Max accuracy :  0.96625\n",
      "740 Avg Loss :  0.08407308064800295 Train Loss :  1.9622344  Train accuracy :  0.95625  Max accuracy :  0.96625\n",
      "750 Avg Loss :  0.08637792400882713 Train Loss :  1.3884348  Train accuracy :  0.94375  Max accuracy :  0.96625\n",
      "760 Avg Loss :  0.09319527753229653 Train Loss :  0.67471987  Train accuracy :  0.965  Max accuracy :  0.96625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "770 Avg Loss :  0.10153851012832353 Train Loss :  1.1644766  Train accuracy :  0.9575  Max accuracy :  0.96625\n",
      "780 Avg Loss :  0.28740829645123867 Train Loss :  0.3162623  Train accuracy :  0.9575  Max accuracy :  0.96625\n",
      "790 Avg Loss :  0.07265072705091112 Train Loss :  0.6536463  Train accuracy :  0.9625  Max accuracy :  0.96625\n",
      "800 Avg Loss :  0.10203561106962816 Train Loss :  0.46715027  Train accuracy :  0.9425  Max accuracy :  0.96625\n",
      "810 Avg Loss :  0.1215476825766798 Train Loss :  0.7353142  Train accuracy :  0.95375  Max accuracy :  0.96625\n",
      "820 Avg Loss :  0.18479431896204399 Train Loss :  0.24059057  Train accuracy :  0.95  Max accuracy :  0.96625\n",
      "830 Avg Loss :  0.1495132252707013 Train Loss :  0.23253307  Train accuracy :  0.96125  Max accuracy :  0.96625\n",
      "840 Avg Loss :  0.07755708120696779 Train Loss :  0.30127665  Train accuracy :  0.95375  Max accuracy :  0.96625\n",
      "850 Avg Loss :  0.07075169042218474 Train Loss :  0.60426795  Train accuracy :  0.96125  Max accuracy :  0.96625\n",
      "860 Avg Loss :  0.08717036649717816 Train Loss :  0.28664884  Train accuracy :  0.96125  Max accuracy :  0.96625\n",
      "870 Avg Loss :  0.08349736101393189 Train Loss :  0.8608112  Train accuracy :  0.95625  Max accuracy :  0.96625\n",
      "880 Avg Loss :  0.08536101491855722 Train Loss :  0.20439453  Train accuracy :  0.96375  Max accuracy :  0.96625\n",
      "890 Avg Loss :  0.07826852954791061 Train Loss :  0.31569412  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "900 Avg Loss :  0.1110307260283402 Train Loss :  0.29309317  Train accuracy :  0.96  Max accuracy :  0.96625\n",
      "910 Avg Loss :  0.14286295095059484 Train Loss :  0.7397717  Train accuracy :  0.965  Max accuracy :  0.96625\n",
      "920 Avg Loss :  0.09504144711952127 Train Loss :  0.7390099  Train accuracy :  0.96  Max accuracy :  0.96625\n",
      "930 Avg Loss :  0.08857681527401187 Train Loss :  1.0658702  Train accuracy :  0.955  Max accuracy :  0.96625\n",
      "940 Avg Loss :  0.07960627534027608 Train Loss :  1.1424724  Train accuracy :  0.96  Max accuracy :  0.96625\n",
      "950 Avg Loss :  0.13732311583589762 Train Loss :  0.4021083  Train accuracy :  0.95625  Max accuracy :  0.96625\n",
      "960 Avg Loss :  0.21490828360297853 Train Loss :  0.576517  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "970 Avg Loss :  0.06756758415472827 Train Loss :  1.0020591  Train accuracy :  0.95875  Max accuracy :  0.96625\n",
      "980 Avg Loss :  0.11465234943066858 Train Loss :  0.63621706  Train accuracy :  0.96  Max accuracy :  0.96625\n",
      "990 Avg Loss :  0.08776931484629003 Train Loss :  0.8187684  Train accuracy :  0.9575  Max accuracy :  0.96625\n",
      "INFO:tensorflow:Restoring parameters from ./mymodel_final.ckpt\n",
      "DNN result\n",
      "[[506  20]\n",
      " [ 14 260]]\n",
      "0.9575\n",
      "XGB result\n",
      "[[511  15]\n",
      " [ 21 253]]\n",
      "0.955\n",
      "RF result\n",
      "[[514  12]\n",
      " [ 19 255]]\n",
      "0.96125\n",
      "SVM result\n",
      "[[518   8]\n",
      " [ 22 252]]\n",
      "0.9625\n",
      "EN result\n",
      "[[512  14]\n",
      " [ 12 262]]\n",
      "0.9675\n",
      "0 Avg Loss :  0.3040205204327191 Train Loss :  0.15359038  Train accuracy :  0.93625  Max accuracy :  0.93625\n",
      "10 Avg Loss :  0.10549575842118693 Train Loss :  0.1386951  Train accuracy :  0.95625  Max accuracy :  0.95625\n",
      "20 Avg Loss :  0.10385619922141939 Train Loss :  0.15884925  Train accuracy :  0.94875  Max accuracy :  0.95625\n",
      "30 Avg Loss :  0.08809494388489321 Train Loss :  0.13086993  Train accuracy :  0.94875  Max accuracy :  0.95625\n",
      "40 Avg Loss :  0.08365292443029053 Train Loss :  0.1527051  Train accuracy :  0.9525  Max accuracy :  0.95625\n",
      "50 Avg Loss :  0.08461739254250587 Train Loss :  0.11209747  Train accuracy :  0.96  Max accuracy :  0.96\n",
      "60 Avg Loss :  0.085158044871475 Train Loss :  0.14962076  Train accuracy :  0.95875  Max accuracy :  0.96\n",
      "70 Avg Loss :  0.08836405192102707 Train Loss :  0.21928194  Train accuracy :  0.95  Max accuracy :  0.96\n",
      "80 Avg Loss :  0.0845610777780946 Train Loss :  0.14220409  Train accuracy :  0.955  Max accuracy :  0.96\n",
      "90 Avg Loss :  0.08138995338231324 Train Loss :  0.13997567  Train accuracy :  0.955  Max accuracy :  0.96\n",
      "100 Avg Loss :  0.06170828947298494 Train Loss :  0.15107195  Train accuracy :  0.95125  Max accuracy :  0.96\n",
      "110 Avg Loss :  0.06696493720768819 Train Loss :  0.12107784  Train accuracy :  0.9575  Max accuracy :  0.96\n",
      "120 Avg Loss :  0.059572734520770596 Train Loss :  0.17185798  Train accuracy :  0.95125  Max accuracy :  0.96\n",
      "130 Avg Loss :  0.06690808709910406 Train Loss :  0.14473999  Train accuracy :  0.95375  Max accuracy :  0.96\n",
      "140 Avg Loss :  0.07880810365479969 Train Loss :  0.13432012  Train accuracy :  0.96  Max accuracy :  0.96\n",
      "150 Avg Loss :  0.06647067069674707 Train Loss :  0.20437185  Train accuracy :  0.95  Max accuracy :  0.96\n",
      "160 Avg Loss :  0.0915892586511161 Train Loss :  0.3652124  Train accuracy :  0.95375  Max accuracy :  0.96\n",
      "170 Avg Loss :  0.05931277288722673 Train Loss :  0.24478795  Train accuracy :  0.96  Max accuracy :  0.96\n",
      "180 Avg Loss :  0.0695196959589209 Train Loss :  0.15752709  Train accuracy :  0.95375  Max accuracy :  0.96\n",
      "190 Avg Loss :  0.11889727160866771 Train Loss :  0.14204217  Train accuracy :  0.9325  Max accuracy :  0.96\n",
      "200 Avg Loss :  0.074937740540398 Train Loss :  0.19278438  Train accuracy :  0.95375  Max accuracy :  0.96\n",
      "210 Avg Loss :  0.08189305736284169 Train Loss :  0.24397373  Train accuracy :  0.955  Max accuracy :  0.96\n",
      "220 Avg Loss :  0.07913060449729012 Train Loss :  0.13225122  Train accuracy :  0.95875  Max accuracy :  0.96\n",
      "230 Avg Loss :  0.053046613241479336 Train Loss :  0.19287437  Train accuracy :  0.9625  Max accuracy :  0.9625\n",
      "240 Avg Loss :  0.06721912043368711 Train Loss :  0.115748025  Train accuracy :  0.9575  Max accuracy :  0.9625\n",
      "250 Avg Loss :  0.06555052700319461 Train Loss :  0.09509407  Train accuracy :  0.965  Max accuracy :  0.965\n",
      "260 Avg Loss :  0.0881796218454838 Train Loss :  0.22609656  Train accuracy :  0.9675  Max accuracy :  0.9675\n",
      "270 Avg Loss :  0.057156693655997494 Train Loss :  0.14041343  Train accuracy :  0.9625  Max accuracy :  0.9675\n",
      "280 Avg Loss :  0.0904166422052575 Train Loss :  0.21748456  Train accuracy :  0.96  Max accuracy :  0.9675\n",
      "290 Avg Loss :  0.07119937164575929 Train Loss :  0.15814959  Train accuracy :  0.96  Max accuracy :  0.9675\n",
      "300 Avg Loss :  0.06433101592119783 Train Loss :  0.23962316  Train accuracy :  0.965  Max accuracy :  0.9675\n",
      "310 Avg Loss :  0.0803699175760682 Train Loss :  0.3002898  Train accuracy :  0.9575  Max accuracy :  0.9675\n",
      "320 Avg Loss :  0.061252419470942454 Train Loss :  0.23101024  Train accuracy :  0.95625  Max accuracy :  0.9675\n",
      "330 Avg Loss :  0.10006843066574739 Train Loss :  0.15932183  Train accuracy :  0.955  Max accuracy :  0.9675\n",
      "340 Avg Loss :  0.07430091718145247 Train Loss :  0.16474853  Train accuracy :  0.96  Max accuracy :  0.9675\n",
      "350 Avg Loss :  0.07064780907239766 Train Loss :  0.1531204  Train accuracy :  0.96375  Max accuracy :  0.9675\n",
      "360 Avg Loss :  0.07184148297112967 Train Loss :  0.28486308  Train accuracy :  0.95125  Max accuracy :  0.9675\n",
      "370 Avg Loss :  0.06690940330736339 Train Loss :  0.23374844  Train accuracy :  0.9575  Max accuracy :  0.9675\n",
      "380 Avg Loss :  0.058662849145808375 Train Loss :  0.1440682  Train accuracy :  0.9625  Max accuracy :  0.9675\n",
      "390 Avg Loss :  0.0766072000676234 Train Loss :  0.22684506  Train accuracy :  0.955  Max accuracy :  0.9675\n",
      "400 Avg Loss :  0.07610612548887734 Train Loss :  0.24584663  Train accuracy :  0.955  Max accuracy :  0.9675\n",
      "410 Avg Loss :  0.12175841576286722 Train Loss :  0.18752228  Train accuracy :  0.95625  Max accuracy :  0.9675\n",
      "420 Avg Loss :  0.09969452457569009 Train Loss :  0.23328312  Train accuracy :  0.95875  Max accuracy :  0.9675\n",
      "430 Avg Loss :  0.08951775864365376 Train Loss :  0.16137543  Train accuracy :  0.96375  Max accuracy :  0.9675\n",
      "440 Avg Loss :  0.067866802365253 Train Loss :  0.23167992  Train accuracy :  0.9525  Max accuracy :  0.9675\n",
      "450 Avg Loss :  0.06279728508421352 Train Loss :  0.27557942  Train accuracy :  0.95  Max accuracy :  0.9675\n",
      "460 Avg Loss :  0.0651855295457478 Train Loss :  0.29405597  Train accuracy :  0.96375  Max accuracy :  0.9675\n",
      "470 Avg Loss :  0.24382066360807841 Train Loss :  0.19700405  Train accuracy :  0.95  Max accuracy :  0.9675\n",
      "480 Avg Loss :  0.09199914224778435 Train Loss :  0.2979641  Train accuracy :  0.955  Max accuracy :  0.9675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490 Avg Loss :  0.09278434767786946 Train Loss :  0.29192  Train accuracy :  0.955  Max accuracy :  0.9675\n",
      "500 Avg Loss :  0.06638539597458606 Train Loss :  0.19653761  Train accuracy :  0.96  Max accuracy :  0.9675\n",
      "510 Avg Loss :  0.0887651229277253 Train Loss :  0.16110711  Train accuracy :  0.955  Max accuracy :  0.9675\n",
      "520 Avg Loss :  0.06296840045667652 Train Loss :  0.19985272  Train accuracy :  0.9575  Max accuracy :  0.9675\n",
      "530 Avg Loss :  0.10317007236049645 Train Loss :  0.38613105  Train accuracy :  0.955  Max accuracy :  0.9675\n",
      "540 Avg Loss :  0.0699477252284331 Train Loss :  0.19048886  Train accuracy :  0.95  Max accuracy :  0.9675\n",
      "550 Avg Loss :  0.10129424778278917 Train Loss :  0.35563305  Train accuracy :  0.95375  Max accuracy :  0.9675\n",
      "560 Avg Loss :  0.065388245075675 Train Loss :  0.25436297  Train accuracy :  0.95125  Max accuracy :  0.9675\n",
      "570 Avg Loss :  0.09763012959488802 Train Loss :  0.16681719  Train accuracy :  0.95625  Max accuracy :  0.9675\n",
      "580 Avg Loss :  0.08184998477476517 Train Loss :  0.18342939  Train accuracy :  0.95375  Max accuracy :  0.9675\n",
      "590 Avg Loss :  0.08449137067821409 Train Loss :  0.32208446  Train accuracy :  0.9525  Max accuracy :  0.9675\n",
      "600 Avg Loss :  0.08346469409298156 Train Loss :  0.3044901  Train accuracy :  0.9575  Max accuracy :  0.9675\n",
      "610 Avg Loss :  0.05632615950889886 Train Loss :  0.2980836  Train accuracy :  0.95  Max accuracy :  0.9675\n",
      "620 Avg Loss :  0.07490589344940547 Train Loss :  0.17836982  Train accuracy :  0.95375  Max accuracy :  0.9675\n",
      "630 Avg Loss :  0.06714237473040288 Train Loss :  0.2232768  Train accuracy :  0.955  Max accuracy :  0.9675\n",
      "640 Avg Loss :  0.16434947321457521 Train Loss :  0.23023215  Train accuracy :  0.94375  Max accuracy :  0.9675\n",
      "650 Avg Loss :  0.0657046287752954 Train Loss :  0.40226996  Train accuracy :  0.95  Max accuracy :  0.9675\n",
      "660 Avg Loss :  0.059877362077324005 Train Loss :  0.24527949  Train accuracy :  0.95375  Max accuracy :  0.9675\n",
      "670 Avg Loss :  0.07946843610677334 Train Loss :  0.25615892  Train accuracy :  0.94625  Max accuracy :  0.9675\n",
      "680 Avg Loss :  0.06852250709198417 Train Loss :  0.18505622  Train accuracy :  0.95875  Max accuracy :  0.9675\n",
      "690 Avg Loss :  0.0754626122236784 Train Loss :  0.2761922  Train accuracy :  0.95  Max accuracy :  0.9675\n",
      "700 Avg Loss :  0.09389537945389745 Train Loss :  0.41622344  Train accuracy :  0.95  Max accuracy :  0.9675\n",
      "710 Avg Loss :  0.07830487093555606 Train Loss :  0.5182713  Train accuracy :  0.955  Max accuracy :  0.9675\n",
      "720 Avg Loss :  0.06457528285682201 Train Loss :  0.23300482  Train accuracy :  0.96  Max accuracy :  0.9675\n",
      "730 Avg Loss :  0.07342339373592818 Train Loss :  0.28860387  Train accuracy :  0.9575  Max accuracy :  0.9675\n",
      "740 Avg Loss :  0.07199390029667745 Train Loss :  0.58172894  Train accuracy :  0.9375  Max accuracy :  0.9675\n",
      "750 Avg Loss :  0.06505965663486028 Train Loss :  0.17120041  Train accuracy :  0.96125  Max accuracy :  0.9675\n",
      "760 Avg Loss :  0.07798679274440344 Train Loss :  0.24879757  Train accuracy :  0.95625  Max accuracy :  0.9675\n",
      "770 Avg Loss :  0.10129879519809039 Train Loss :  0.23563206  Train accuracy :  0.96  Max accuracy :  0.9675\n",
      "780 Avg Loss :  0.08589111960359984 Train Loss :  0.16317962  Train accuracy :  0.94875  Max accuracy :  0.9675\n",
      "790 Avg Loss :  0.07051407446020416 Train Loss :  0.23185253  Train accuracy :  0.95875  Max accuracy :  0.9675\n",
      "800 Avg Loss :  0.06493928767408112 Train Loss :  0.26755017  Train accuracy :  0.9525  Max accuracy :  0.9675\n",
      "810 Avg Loss :  0.14142654094445922 Train Loss :  0.3874147  Train accuracy :  0.95625  Max accuracy :  0.9675\n",
      "820 Avg Loss :  0.09049491125292013 Train Loss :  0.1625511  Train accuracy :  0.95875  Max accuracy :  0.9675\n",
      "830 Avg Loss :  0.06761287156093335 Train Loss :  0.23838608  Train accuracy :  0.95375  Max accuracy :  0.9675\n",
      "840 Avg Loss :  0.06349915147958587 Train Loss :  0.18553685  Train accuracy :  0.955  Max accuracy :  0.9675\n",
      "850 Avg Loss :  0.0845439595037273 Train Loss :  0.6072902  Train accuracy :  0.94875  Max accuracy :  0.9675\n",
      "860 Avg Loss :  0.09530873047853154 Train Loss :  0.30916116  Train accuracy :  0.95375  Max accuracy :  0.9675\n",
      "870 Avg Loss :  0.09700811955346059 Train Loss :  0.33977547  Train accuracy :  0.9575  Max accuracy :  0.9675\n",
      "880 Avg Loss :  0.052987842421446524 Train Loss :  0.17552552  Train accuracy :  0.96625  Max accuracy :  0.9675\n",
      "890 Avg Loss :  0.08799193342981326 Train Loss :  0.19194871  Train accuracy :  0.955  Max accuracy :  0.9675\n",
      "900 Avg Loss :  0.08500164422938335 Train Loss :  0.24264236  Train accuracy :  0.95875  Max accuracy :  0.9675\n",
      "910 Avg Loss :  0.07586950933494208 Train Loss :  0.20998062  Train accuracy :  0.955  Max accuracy :  0.9675\n",
      "920 Avg Loss :  0.09842235698098581 Train Loss :  0.20341371  Train accuracy :  0.9525  Max accuracy :  0.9675\n",
      "930 Avg Loss :  0.10509858629666269 Train Loss :  0.13894361  Train accuracy :  0.9525  Max accuracy :  0.9675\n",
      "940 Avg Loss :  0.12843915277958984 Train Loss :  0.22268297  Train accuracy :  0.9525  Max accuracy :  0.9675\n",
      "950 Avg Loss :  0.08316365809046795 Train Loss :  0.24400733  Train accuracy :  0.9575  Max accuracy :  0.9675\n",
      "960 Avg Loss :  0.05576872823959483 Train Loss :  0.35028648  Train accuracy :  0.9575  Max accuracy :  0.9675\n",
      "970 Avg Loss :  0.08987574357472894 Train Loss :  0.1975028  Train accuracy :  0.95  Max accuracy :  0.9675\n",
      "980 Avg Loss :  0.06616558097968146 Train Loss :  0.50138557  Train accuracy :  0.945  Max accuracy :  0.9675\n",
      "990 Avg Loss :  0.07011200524201351 Train Loss :  0.30936503  Train accuracy :  0.9525  Max accuracy :  0.9675\n",
      "INFO:tensorflow:Restoring parameters from ./mymodel_final.ckpt\n",
      "DNN result\n",
      "[[511  15]\n",
      " [ 24 250]]\n",
      "0.95125\n",
      "XGB result\n",
      "[[505  21]\n",
      " [ 14 260]]\n",
      "0.95625\n",
      "RF result\n",
      "[[512  14]\n",
      " [ 15 259]]\n",
      "0.96375\n",
      "SVM result\n",
      "[[510  16]\n",
      " [ 13 261]]\n",
      "0.96375\n",
      "EN result\n",
      "[[508  18]\n",
      " [ 11 263]]\n",
      "0.96375\n",
      "0 Avg Loss :  0.42209476418793207 Train Loss :  0.15462139  Train accuracy :  0.94493115  Max accuracy :  0.94493115\n",
      "10 Avg Loss :  0.11043163349053692 Train Loss :  0.17224842  Train accuracy :  0.95244056  Max accuracy :  0.95244056\n",
      "20 Avg Loss :  0.10205329312676831 Train Loss :  0.23502138  Train accuracy :  0.9386733  Max accuracy :  0.95244056\n",
      "30 Avg Loss :  0.09976053138130475 Train Loss :  0.16960339  Train accuracy :  0.9574468  Max accuracy :  0.9574468\n",
      "40 Avg Loss :  0.09912396325463693 Train Loss :  0.18545458  Train accuracy :  0.95369214  Max accuracy :  0.9574468\n",
      "50 Avg Loss :  0.09097747671018755 Train Loss :  0.24670765  Train accuracy :  0.951189  Max accuracy :  0.9574468\n",
      "60 Avg Loss :  0.1018703183092709 Train Loss :  0.2141435  Train accuracy :  0.951189  Max accuracy :  0.9574468\n",
      "70 Avg Loss :  0.08135969447903336 Train Loss :  0.22241451  Train accuracy :  0.95369214  Max accuracy :  0.9574468\n",
      "80 Avg Loss :  0.07581172065277185 Train Loss :  0.2340311  Train accuracy :  0.9574468  Max accuracy :  0.9574468\n",
      "90 Avg Loss :  0.08358341954382402 Train Loss :  0.27294904  Train accuracy :  0.9586984  Max accuracy :  0.9586984\n",
      "100 Avg Loss :  0.0694850060224001 Train Loss :  0.24178466  Train accuracy :  0.9499374  Max accuracy :  0.9586984\n",
      "110 Avg Loss :  0.0995334852819464 Train Loss :  0.27309385  Train accuracy :  0.9474343  Max accuracy :  0.9586984\n",
      "120 Avg Loss :  0.08048089986134854 Train Loss :  0.22184835  Train accuracy :  0.9574468  Max accuracy :  0.9586984\n",
      "130 Avg Loss :  0.07379684853367506 Train Loss :  0.29163358  Train accuracy :  0.95369214  Max accuracy :  0.9586984\n",
      "140 Avg Loss :  0.08388388113650892 Train Loss :  0.31391627  Train accuracy :  0.94242805  Max accuracy :  0.9586984\n",
      "150 Avg Loss :  0.0945239165698045 Train Loss :  0.20705499  Train accuracy :  0.9674593  Max accuracy :  0.9674593\n",
      "160 Avg Loss :  0.07177723403687453 Train Loss :  0.5379216  Train accuracy :  0.951189  Max accuracy :  0.9674593\n",
      "170 Avg Loss :  0.06728443443509084 Train Loss :  0.34519345  Train accuracy :  0.951189  Max accuracy :  0.9674593\n",
      "180 Avg Loss :  0.08885876092660638 Train Loss :  0.51823  Train accuracy :  0.9574468  Max accuracy :  0.9674593\n",
      "190 Avg Loss :  0.0806147716274219 Train Loss :  0.6648505  Train accuracy :  0.9499374  Max accuracy :  0.9674593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 Avg Loss :  0.07059706278544452 Train Loss :  0.3489248  Train accuracy :  0.96245307  Max accuracy :  0.9674593\n",
      "210 Avg Loss :  0.06712599551039082 Train Loss :  0.3832536  Train accuracy :  0.951189  Max accuracy :  0.9674593\n",
      "220 Avg Loss :  0.07214650322150971 Train Loss :  0.362538  Train accuracy :  0.951189  Max accuracy :  0.9674593\n",
      "230 Avg Loss :  0.057870531005651815 Train Loss :  0.28632796  Train accuracy :  0.95244056  Max accuracy :  0.9674593\n",
      "240 Avg Loss :  0.08099708170630038 Train Loss :  0.33889782  Train accuracy :  0.95244056  Max accuracy :  0.9674593\n",
      "250 Avg Loss :  0.06987770264303045 Train Loss :  0.34803164  Train accuracy :  0.9499374  Max accuracy :  0.9674593\n",
      "260 Avg Loss :  0.06217166507017931 Train Loss :  0.39020807  Train accuracy :  0.9474343  Max accuracy :  0.9674593\n",
      "270 Avg Loss :  0.07682410449654395 Train Loss :  0.2172195  Train accuracy :  0.9474343  Max accuracy :  0.9674593\n",
      "280 Avg Loss :  0.07221841625869273 Train Loss :  0.22332527  Train accuracy :  0.95244056  Max accuracy :  0.9674593\n",
      "290 Avg Loss :  0.08623086404986681 Train Loss :  0.3310593  Train accuracy :  0.9399249  Max accuracy :  0.9674593\n",
      "300 Avg Loss :  0.07025792664249561 Train Loss :  0.32410222  Train accuracy :  0.95244056  Max accuracy :  0.9674593\n",
      "310 Avg Loss :  0.10313399671576914 Train Loss :  0.35731757  Train accuracy :  0.95494366  Max accuracy :  0.9674593\n",
      "320 Avg Loss :  0.06911914800626359 Train Loss :  0.22119828  Train accuracy :  0.9499374  Max accuracy :  0.9674593\n",
      "330 Avg Loss :  0.10875248275364616 Train Loss :  1.1067132  Train accuracy :  0.9599499  Max accuracy :  0.9674593\n",
      "340 Avg Loss :  0.10120371359932637 Train Loss :  0.36028162  Train accuracy :  0.9574468  Max accuracy :  0.9674593\n",
      "350 Avg Loss :  0.11302508540185432 Train Loss :  0.5860857  Train accuracy :  0.9486859  Max accuracy :  0.9674593\n",
      "360 Avg Loss :  0.0655856980010867 Train Loss :  0.4898218  Train accuracy :  0.951189  Max accuracy :  0.9674593\n",
      "370 Avg Loss :  0.0726370928376647 Train Loss :  0.9380894  Train accuracy :  0.951189  Max accuracy :  0.9674593\n",
      "380 Avg Loss :  0.07646654200341022 Train Loss :  0.642025  Train accuracy :  0.95494366  Max accuracy :  0.9674593\n",
      "390 Avg Loss :  0.06786736523333403 Train Loss :  0.36625308  Train accuracy :  0.9474343  Max accuracy :  0.9674593\n",
      "400 Avg Loss :  0.05358378542587161 Train Loss :  0.41765878  Train accuracy :  0.95619524  Max accuracy :  0.9674593\n",
      "410 Avg Loss :  0.06364873818321419 Train Loss :  1.2485888  Train accuracy :  0.9599499  Max accuracy :  0.9674593\n",
      "420 Avg Loss :  0.06466790288686754 Train Loss :  0.77317256  Train accuracy :  0.9486859  Max accuracy :  0.9674593\n",
      "430 Avg Loss :  0.06408199877478181 Train Loss :  0.27959296  Train accuracy :  0.95244056  Max accuracy :  0.9674593\n",
      "440 Avg Loss :  0.06874628315147545 Train Loss :  0.7245835  Train accuracy :  0.9574468  Max accuracy :  0.9674593\n",
      "450 Avg Loss :  0.06169751763809474 Train Loss :  0.45757025  Train accuracy :  0.95244056  Max accuracy :  0.9674593\n",
      "460 Avg Loss :  0.10060079452315607 Train Loss :  0.7338188  Train accuracy :  0.95244056  Max accuracy :  0.9674593\n",
      "470 Avg Loss :  0.08728044036044073 Train Loss :  0.4000761  Train accuracy :  0.95619524  Max accuracy :  0.9674593\n",
      "480 Avg Loss :  0.08667065070143767 Train Loss :  0.37503213  Train accuracy :  0.9586984  Max accuracy :  0.9674593\n",
      "490 Avg Loss :  0.08373537057611559 Train Loss :  0.4813799  Train accuracy :  0.95619524  Max accuracy :  0.9674593\n",
      "500 Avg Loss :  0.06477607911386127 Train Loss :  0.35121748  Train accuracy :  0.95619524  Max accuracy :  0.9674593\n",
      "510 Avg Loss :  0.05986649165528695 Train Loss :  0.55697906  Train accuracy :  0.95244056  Max accuracy :  0.9674593\n",
      "520 Avg Loss :  0.09211746214090717 Train Loss :  0.56682265  Train accuracy :  0.95369214  Max accuracy :  0.9674593\n",
      "530 Avg Loss :  0.10001305294489221 Train Loss :  0.35548556  Train accuracy :  0.9499374  Max accuracy :  0.9674593\n",
      "540 Avg Loss :  0.06972156009370728 Train Loss :  0.39016828  Train accuracy :  0.9486859  Max accuracy :  0.9674593\n",
      "550 Avg Loss :  0.06909761165401765 Train Loss :  0.35430884  Train accuracy :  0.951189  Max accuracy :  0.9674593\n",
      "560 Avg Loss :  0.06289907313683735 Train Loss :  0.46553028  Train accuracy :  0.95244056  Max accuracy :  0.9674593\n",
      "570 Avg Loss :  0.07477809061362807 Train Loss :  1.4181932  Train accuracy :  0.951189  Max accuracy :  0.9674593\n",
      "580 Avg Loss :  0.05957896834505456 Train Loss :  1.2110207  Train accuracy :  0.9586984  Max accuracy :  0.9674593\n",
      "590 Avg Loss :  0.07735762974646472 Train Loss :  0.31322366  Train accuracy :  0.951189  Max accuracy :  0.9674593\n",
      "600 Avg Loss :  0.10420542424877308 Train Loss :  0.28320646  Train accuracy :  0.95619524  Max accuracy :  0.9674593\n",
      "610 Avg Loss :  0.09623983086618997 Train Loss :  0.19966267  Train accuracy :  0.95494366  Max accuracy :  0.9674593\n",
      "620 Avg Loss :  0.09177722490858285 Train Loss :  0.19722576  Train accuracy :  0.95494366  Max accuracy :  0.9674593\n",
      "630 Avg Loss :  0.08915031526703387 Train Loss :  0.41059023  Train accuracy :  0.9461827  Max accuracy :  0.9674593\n",
      "640 Avg Loss :  0.079421732874055 Train Loss :  0.35363516  Train accuracy :  0.9461827  Max accuracy :  0.9674593\n",
      "650 Avg Loss :  0.10511113111195819 Train Loss :  0.19513796  Train accuracy :  0.951189  Max accuracy :  0.9674593\n",
      "660 Avg Loss :  0.09669945182810935 Train Loss :  0.2770896  Train accuracy :  0.9486859  Max accuracy :  0.9674593\n",
      "670 Avg Loss :  0.06392682503376687 Train Loss :  0.3136057  Train accuracy :  0.9474343  Max accuracy :  0.9674593\n",
      "680 Avg Loss :  0.10930385236029648 Train Loss :  0.31710535  Train accuracy :  0.94493115  Max accuracy :  0.9674593\n",
      "690 Avg Loss :  0.06504645564460326 Train Loss :  0.19301353  Train accuracy :  0.9461827  Max accuracy :  0.9674593\n",
      "700 Avg Loss :  0.07498463050329258 Train Loss :  0.36151907  Train accuracy :  0.9474343  Max accuracy :  0.9674593\n",
      "710 Avg Loss :  0.08650801127909548 Train Loss :  0.55060786  Train accuracy :  0.9499374  Max accuracy :  0.9674593\n",
      "720 Avg Loss :  0.08120211719402244 Train Loss :  0.3327786  Train accuracy :  0.94493115  Max accuracy :  0.9674593\n",
      "730 Avg Loss :  0.10874083071082295 Train Loss :  0.38418132  Train accuracy :  0.951189  Max accuracy :  0.9674593\n",
      "740 Avg Loss :  0.12231515328000699 Train Loss :  0.36462474  Train accuracy :  0.9486859  Max accuracy :  0.9674593\n",
      "750 Avg Loss :  0.10403848103513673 Train Loss :  0.550267  Train accuracy :  0.9486859  Max accuracy :  0.9674593\n",
      "760 Avg Loss :  0.11545098898932335 Train Loss :  0.3418993  Train accuracy :  0.9486859  Max accuracy :  0.9674593\n",
      "770 Avg Loss :  0.07377070474571419 Train Loss :  1.1288226  Train accuracy :  0.951189  Max accuracy :  0.9674593\n",
      "780 Avg Loss :  0.06643206719309092 Train Loss :  0.55774295  Train accuracy :  0.95244056  Max accuracy :  0.9674593\n",
      "790 Avg Loss :  0.07057889284832135 Train Loss :  0.37062135  Train accuracy :  0.9474343  Max accuracy :  0.9674593\n",
      "800 Avg Loss :  0.10430737265518733 Train Loss :  0.7399441  Train accuracy :  0.9474343  Max accuracy :  0.9674593\n",
      "810 Avg Loss :  0.06603899661318528 Train Loss :  0.39017174  Train accuracy :  0.95244056  Max accuracy :  0.9674593\n",
      "820 Avg Loss :  0.06712754473223216 Train Loss :  0.44443798  Train accuracy :  0.9486859  Max accuracy :  0.9674593\n",
      "830 Avg Loss :  0.07096771013623636 Train Loss :  0.48102686  Train accuracy :  0.951189  Max accuracy :  0.9674593\n",
      "840 Avg Loss :  0.11139614535828254 Train Loss :  0.5229619  Train accuracy :  0.951189  Max accuracy :  0.9674593\n",
      "850 Avg Loss :  0.06575243861880153 Train Loss :  0.4703748  Train accuracy :  0.95619524  Max accuracy :  0.9674593\n",
      "860 Avg Loss :  0.08788355471499797 Train Loss :  0.35754123  Train accuracy :  0.9574468  Max accuracy :  0.9674593\n",
      "870 Avg Loss :  0.0676781460476507 Train Loss :  0.59630066  Train accuracy :  0.95619524  Max accuracy :  0.9674593\n",
      "880 Avg Loss :  0.07134034669226304 Train Loss :  0.3596285  Train accuracy :  0.9486859  Max accuracy :  0.9674593\n",
      "890 Avg Loss :  0.07766807761176359 Train Loss :  0.24668337  Train accuracy :  0.9486859  Max accuracy :  0.9674593\n",
      "900 Avg Loss :  0.0714694877720571 Train Loss :  0.22950923  Train accuracy :  0.94493115  Max accuracy :  0.9674593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910 Avg Loss :  0.09441493554706021 Train Loss :  0.29829982  Train accuracy :  0.9474343  Max accuracy :  0.9674593\n",
      "920 Avg Loss :  0.056685189899456305 Train Loss :  0.46563816  Train accuracy :  0.951189  Max accuracy :  0.9674593\n",
      "930 Avg Loss :  0.07127724368391293 Train Loss :  0.3725925  Train accuracy :  0.95494366  Max accuracy :  0.9674593\n",
      "940 Avg Loss :  0.06975125842395105 Train Loss :  0.36207178  Train accuracy :  0.951189  Max accuracy :  0.9674593\n",
      "950 Avg Loss :  0.12159602590171355 Train Loss :  0.5248697  Train accuracy :  0.9474343  Max accuracy :  0.9674593\n",
      "960 Avg Loss :  0.07252758402111278 Train Loss :  0.49597397  Train accuracy :  0.9461827  Max accuracy :  0.9674593\n",
      "970 Avg Loss :  0.07552384187666965 Train Loss :  0.20968331  Train accuracy :  0.95369214  Max accuracy :  0.9674593\n",
      "980 Avg Loss :  0.06772848887235992 Train Loss :  0.58292127  Train accuracy :  0.9461827  Max accuracy :  0.9674593\n",
      "990 Avg Loss :  0.1123651791962662 Train Loss :  0.25107324  Train accuracy :  0.9461827  Max accuracy :  0.9674593\n",
      "INFO:tensorflow:Restoring parameters from ./mymodel_final.ckpt\n",
      "DNN result\n",
      "[[506  20]\n",
      " [ 17 256]]\n",
      "0.9536921151439299\n",
      "XGB result\n",
      "[[505  21]\n",
      " [ 12 261]]\n",
      "0.9586983729662077\n",
      "RF result\n",
      "[[507  19]\n",
      " [ 12 261]]\n",
      "0.9612015018773467\n",
      "SVM result\n",
      "[[510  16]\n",
      " [ 13 260]]\n",
      "0.9637046307884856\n",
      "EN result\n",
      "[[506  20]\n",
      " [  9 264]]\n",
      "0.9637046307884856\n",
      "0 Avg Loss :  0.4637919200052107 Train Loss :  0.14312841  Train accuracy :  0.9411765  Max accuracy :  0.9411765\n",
      "10 Avg Loss :  0.11440296155134483 Train Loss :  0.13292743  Train accuracy :  0.95369214  Max accuracy :  0.95369214\n",
      "20 Avg Loss :  0.10524441029078194 Train Loss :  0.13912779  Train accuracy :  0.9574468  Max accuracy :  0.9574468\n",
      "30 Avg Loss :  0.10465008153447089 Train Loss :  0.1629299  Train accuracy :  0.9474343  Max accuracy :  0.9574468\n",
      "40 Avg Loss :  0.09233374554397802 Train Loss :  0.16686408  Train accuracy :  0.95619524  Max accuracy :  0.9574468\n",
      "50 Avg Loss :  0.09868542011827232 Train Loss :  0.2666664  Train accuracy :  0.94242805  Max accuracy :  0.9574468\n",
      "60 Avg Loss :  0.09327242257339614 Train Loss :  0.21667263  Train accuracy :  0.9499374  Max accuracy :  0.9574468\n",
      "70 Avg Loss :  0.09057090581128634 Train Loss :  0.20857532  Train accuracy :  0.9474343  Max accuracy :  0.9574468\n",
      "80 Avg Loss :  0.10885519195081932 Train Loss :  0.26872602  Train accuracy :  0.9499374  Max accuracy :  0.9574468\n",
      "90 Avg Loss :  0.08569551671722106 Train Loss :  0.22187221  Train accuracy :  0.95619524  Max accuracy :  0.9574468\n",
      "100 Avg Loss :  0.08145687072205225 Train Loss :  0.23207235  Train accuracy :  0.95619524  Max accuracy :  0.9574468\n",
      "110 Avg Loss :  0.07582005003600248 Train Loss :  0.22079182  Train accuracy :  0.9474343  Max accuracy :  0.9574468\n",
      "120 Avg Loss :  0.08297987189143896 Train Loss :  0.2164742  Train accuracy :  0.95494366  Max accuracy :  0.9574468\n",
      "130 Avg Loss :  0.07880181277037733 Train Loss :  0.20874867  Train accuracy :  0.95619524  Max accuracy :  0.9574468\n",
      "140 Avg Loss :  0.08821400936825997 Train Loss :  0.4314804  Train accuracy :  0.951189  Max accuracy :  0.9574468\n",
      "150 Avg Loss :  0.08781001015034107 Train Loss :  0.27548638  Train accuracy :  0.96245307  Max accuracy :  0.96245307\n",
      "160 Avg Loss :  0.07770700581438306 Train Loss :  0.39685658  Train accuracy :  0.95369214  Max accuracy :  0.96245307\n",
      "170 Avg Loss :  0.07712931608382081 Train Loss :  0.2579555  Train accuracy :  0.9586984  Max accuracy :  0.96245307\n",
      "180 Avg Loss :  0.10297299781814219 Train Loss :  0.40177122  Train accuracy :  0.9486859  Max accuracy :  0.96245307\n",
      "190 Avg Loss :  0.10936888184265368 Train Loss :  0.23820402  Train accuracy :  0.95619524  Max accuracy :  0.96245307\n",
      "200 Avg Loss :  0.07949759601615372 Train Loss :  0.37815446  Train accuracy :  0.9612015  Max accuracy :  0.96245307\n",
      "210 Avg Loss :  0.0937027095683983 Train Loss :  0.21917956  Train accuracy :  0.95244056  Max accuracy :  0.96245307\n",
      "220 Avg Loss :  0.08333368872159293 Train Loss :  0.3292487  Train accuracy :  0.95494366  Max accuracy :  0.96245307\n",
      "230 Avg Loss :  0.07380015100352467 Train Loss :  0.37385038  Train accuracy :  0.95244056  Max accuracy :  0.96245307\n",
      "240 Avg Loss :  0.07600662474786597 Train Loss :  0.53278226  Train accuracy :  0.9574468  Max accuracy :  0.96245307\n",
      "250 Avg Loss :  0.07610761613718099 Train Loss :  0.5238006  Train accuracy :  0.95244056  Max accuracy :  0.96245307\n",
      "260 Avg Loss :  0.0747476746328175 Train Loss :  0.4074354  Train accuracy :  0.95244056  Max accuracy :  0.96245307\n",
      "270 Avg Loss :  0.08326982580391426 Train Loss :  0.4587716  Train accuracy :  0.95494366  Max accuracy :  0.96245307\n",
      "280 Avg Loss :  0.07361907375577308 Train Loss :  0.3269971  Train accuracy :  0.95619524  Max accuracy :  0.96245307\n",
      "290 Avg Loss :  0.06242918352862554 Train Loss :  0.25358477  Train accuracy :  0.95369214  Max accuracy :  0.96245307\n",
      "300 Avg Loss :  0.07943429930933882 Train Loss :  0.39890864  Train accuracy :  0.9612015  Max accuracy :  0.96245307\n",
      "310 Avg Loss :  0.0771898592855515 Train Loss :  0.33028892  Train accuracy :  0.951189  Max accuracy :  0.96245307\n",
      "320 Avg Loss :  0.08034245581698736 Train Loss :  0.39714766  Train accuracy :  0.951189  Max accuracy :  0.96245307\n",
      "330 Avg Loss :  0.09449049022181757 Train Loss :  0.3295055  Train accuracy :  0.9499374  Max accuracy :  0.96245307\n",
      "340 Avg Loss :  0.07575428675461027 Train Loss :  0.48017976  Train accuracy :  0.9586984  Max accuracy :  0.96245307\n",
      "350 Avg Loss :  0.07803262331123863 Train Loss :  0.35838526  Train accuracy :  0.9612015  Max accuracy :  0.96245307\n",
      "360 Avg Loss :  0.06126391325545099 Train Loss :  0.45316282  Train accuracy :  0.9612015  Max accuracy :  0.96245307\n",
      "370 Avg Loss :  0.14878009096719322 Train Loss :  0.5786043  Train accuracy :  0.9574468  Max accuracy :  0.96245307\n",
      "380 Avg Loss :  0.07140240405819241 Train Loss :  0.5422105  Train accuracy :  0.9649562  Max accuracy :  0.9649562\n",
      "390 Avg Loss :  0.06270794274418483 Train Loss :  0.27085596  Train accuracy :  0.9599499  Max accuracy :  0.9649562\n",
      "400 Avg Loss :  0.08275002748372834 Train Loss :  0.61920565  Train accuracy :  0.95619524  Max accuracy :  0.9649562\n",
      "410 Avg Loss :  0.07071548281237484 Train Loss :  0.2958508  Train accuracy :  0.95369214  Max accuracy :  0.9649562\n",
      "420 Avg Loss :  0.06740102201833256 Train Loss :  0.36716983  Train accuracy :  0.95619524  Max accuracy :  0.9649562\n",
      "430 Avg Loss :  0.0765410885880036 Train Loss :  0.33447534  Train accuracy :  0.96245307  Max accuracy :  0.9649562\n",
      "440 Avg Loss :  0.12399958712714058 Train Loss :  0.47767118  Train accuracy :  0.9586984  Max accuracy :  0.9649562\n",
      "450 Avg Loss :  0.06258660371947501 Train Loss :  0.20957322  Train accuracy :  0.9574468  Max accuracy :  0.9649562\n",
      "460 Avg Loss :  0.09120301915598766 Train Loss :  0.27072838  Train accuracy :  0.9612015  Max accuracy :  0.9649562\n",
      "470 Avg Loss :  0.073678811346846 Train Loss :  0.33370334  Train accuracy :  0.9586984  Max accuracy :  0.9649562\n",
      "480 Avg Loss :  0.07663126196712251 Train Loss :  0.3145196  Train accuracy :  0.9612015  Max accuracy :  0.9649562\n",
      "490 Avg Loss :  0.06600300332398285 Train Loss :  0.2976181  Train accuracy :  0.9599499  Max accuracy :  0.9649562\n",
      "500 Avg Loss :  0.06924389921394843 Train Loss :  0.34709966  Train accuracy :  0.95494366  Max accuracy :  0.9649562\n",
      "510 Avg Loss :  0.08217271799886867 Train Loss :  0.26370472  Train accuracy :  0.9574468  Max accuracy :  0.9649562\n",
      "520 Avg Loss :  0.06582968003515688 Train Loss :  0.3350698  Train accuracy :  0.9586984  Max accuracy :  0.9649562\n",
      "530 Avg Loss :  0.09122547926381235 Train Loss :  0.7875218  Train accuracy :  0.9486859  Max accuracy :  0.9649562\n",
      "540 Avg Loss :  0.10325036058202382 Train Loss :  0.45289996  Train accuracy :  0.95494366  Max accuracy :  0.9649562\n",
      "550 Avg Loss :  0.10177748829924635 Train Loss :  0.31691292  Train accuracy :  0.94493115  Max accuracy :  0.9649562\n",
      "560 Avg Loss :  0.06452535036286072 Train Loss :  0.3578809  Train accuracy :  0.95369214  Max accuracy :  0.9649562\n",
      "570 Avg Loss :  0.08723670946035 Train Loss :  0.32141984  Train accuracy :  0.95244056  Max accuracy :  0.9649562\n",
      "580 Avg Loss :  0.09686975729086302 Train Loss :  0.68909997  Train accuracy :  0.951189  Max accuracy :  0.9649562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590 Avg Loss :  0.07749136896537884 Train Loss :  0.42331514  Train accuracy :  0.951189  Max accuracy :  0.9649562\n",
      "600 Avg Loss :  0.0970467128790915 Train Loss :  0.91567737  Train accuracy :  0.95619524  Max accuracy :  0.9649562\n",
      "610 Avg Loss :  0.07520839911220326 Train Loss :  0.51367605  Train accuracy :  0.9586984  Max accuracy :  0.9649562\n",
      "620 Avg Loss :  0.06320092524401845 Train Loss :  0.54520184  Train accuracy :  0.95619524  Max accuracy :  0.9649562\n",
      "630 Avg Loss :  0.06230691233317235 Train Loss :  0.72112113  Train accuracy :  0.9599499  Max accuracy :  0.9649562\n",
      "640 Avg Loss :  0.07481923526419063 Train Loss :  0.6690333  Train accuracy :  0.9599499  Max accuracy :  0.9649562\n",
      "650 Avg Loss :  0.057043976025722365 Train Loss :  0.7161486  Train accuracy :  0.9586984  Max accuracy :  0.9649562\n",
      "660 Avg Loss :  0.06052990487244513 Train Loss :  0.42822334  Train accuracy :  0.95244056  Max accuracy :  0.9649562\n",
      "670 Avg Loss :  0.06387489190923845 Train Loss :  0.4831599  Train accuracy :  0.9612015  Max accuracy :  0.9649562\n",
      "680 Avg Loss :  0.06259188303998338 Train Loss :  0.65554553  Train accuracy :  0.9599499  Max accuracy :  0.9649562\n",
      "690 Avg Loss :  0.09367841472184021 Train Loss :  0.96269524  Train accuracy :  0.95494366  Max accuracy :  0.9649562\n",
      "700 Avg Loss :  0.08163183235696383 Train Loss :  0.39744845  Train accuracy :  0.9599499  Max accuracy :  0.9649562\n",
      "710 Avg Loss :  0.05764213272569967 Train Loss :  0.52385545  Train accuracy :  0.9599499  Max accuracy :  0.9649562\n",
      "720 Avg Loss :  0.08285924742397452 Train Loss :  0.2772646  Train accuracy :  0.9586984  Max accuracy :  0.9649562\n",
      "730 Avg Loss :  0.05622261860740504 Train Loss :  0.5284839  Train accuracy :  0.9574468  Max accuracy :  0.9649562\n",
      "740 Avg Loss :  0.06410578523562956 Train Loss :  0.6894318  Train accuracy :  0.95244056  Max accuracy :  0.9649562\n",
      "750 Avg Loss :  0.06100986232714994 Train Loss :  0.67114383  Train accuracy :  0.9612015  Max accuracy :  0.9649562\n",
      "760 Avg Loss :  0.07078357385138849 Train Loss :  0.5339231  Train accuracy :  0.95494366  Max accuracy :  0.9649562\n",
      "770 Avg Loss :  0.07236577996185849 Train Loss :  0.537312  Train accuracy :  0.9599499  Max accuracy :  0.9649562\n",
      "780 Avg Loss :  0.11431239847193604 Train Loss :  1.4998729  Train accuracy :  0.9612015  Max accuracy :  0.9649562\n",
      "790 Avg Loss :  0.08213381386095926 Train Loss :  0.5941336  Train accuracy :  0.9599499  Max accuracy :  0.9649562\n",
      "800 Avg Loss :  0.08357452375016042 Train Loss :  0.52488816  Train accuracy :  0.95619524  Max accuracy :  0.9649562\n",
      "810 Avg Loss :  0.09464337387388307 Train Loss :  0.41748822  Train accuracy :  0.9574468  Max accuracy :  0.9649562\n",
      "820 Avg Loss :  0.1255211592651903 Train Loss :  0.9960994  Train accuracy :  0.9574468  Max accuracy :  0.9649562\n",
      "830 Avg Loss :  0.08701815680667228 Train Loss :  0.66506964  Train accuracy :  0.96245307  Max accuracy :  0.9649562\n",
      "840 Avg Loss :  0.0816642094203936 Train Loss :  0.37838498  Train accuracy :  0.96245307  Max accuracy :  0.9649562\n",
      "850 Avg Loss :  0.10594588034187581 Train Loss :  0.9558827  Train accuracy :  0.951189  Max accuracy :  0.9649562\n",
      "860 Avg Loss :  0.0806413455533662 Train Loss :  0.45742595  Train accuracy :  0.9574468  Max accuracy :  0.9649562\n",
      "870 Avg Loss :  0.06935969271164918 Train Loss :  0.5799193  Train accuracy :  0.9599499  Max accuracy :  0.9649562\n",
      "880 Avg Loss :  0.07150106386481118 Train Loss :  1.0769697  Train accuracy :  0.9612015  Max accuracy :  0.9649562\n",
      "890 Avg Loss :  0.10280679372538416 Train Loss :  0.8646303  Train accuracy :  0.96370465  Max accuracy :  0.9649562\n",
      "900 Avg Loss :  0.12777882317147615 Train Loss :  1.1149133  Train accuracy :  0.9574468  Max accuracy :  0.9649562\n",
      "910 Avg Loss :  0.0909429306630045 Train Loss :  0.59435743  Train accuracy :  0.95619524  Max accuracy :  0.9649562\n",
      "920 Avg Loss :  0.08713592277906301 Train Loss :  1.1453333  Train accuracy :  0.9586984  Max accuracy :  0.9649562\n",
      "930 Avg Loss :  0.11157883339494998 Train Loss :  0.6533537  Train accuracy :  0.9499374  Max accuracy :  0.9649562\n",
      "940 Avg Loss :  0.0698102109267243 Train Loss :  0.48930764  Train accuracy :  0.96245307  Max accuracy :  0.9649562\n",
      "950 Avg Loss :  0.06743369850197009 Train Loss :  0.52689856  Train accuracy :  0.9586984  Max accuracy :  0.9649562\n",
      "960 Avg Loss :  0.07800232284768883 Train Loss :  0.8052321  Train accuracy :  0.96245307  Max accuracy :  0.9649562\n",
      "970 Avg Loss :  0.05565067734901927 Train Loss :  0.72259897  Train accuracy :  0.96370465  Max accuracy :  0.9649562\n",
      "980 Avg Loss :  0.09149212917379501 Train Loss :  0.84192276  Train accuracy :  0.9612015  Max accuracy :  0.9649562\n",
      "990 Avg Loss :  0.18636581900396518 Train Loss :  0.25953367  Train accuracy :  0.9586984  Max accuracy :  0.9649562\n",
      "INFO:tensorflow:Restoring parameters from ./mymodel_final.ckpt\n",
      "DNN result\n",
      "[[516  10]\n",
      " [ 27 246]]\n",
      "0.9536921151439299\n",
      "XGB result\n",
      "[[507  19]\n",
      " [ 15 258]]\n",
      "0.9574468085106383\n",
      "RF result\n",
      "[[515  11]\n",
      " [ 17 256]]\n",
      "0.9649561952440551\n",
      "SVM result\n",
      "[[507  19]\n",
      " [ 15 258]]\n",
      "0.9574468085106383\n",
      "EN result\n",
      "[[508  18]\n",
      " [ 13 260]]\n",
      "0.9612015018773467\n",
      "0 Avg Loss :  0.4023057021466749 Train Loss :  0.13994306  Train accuracy :  0.9486859  Max accuracy :  0.9486859\n",
      "10 Avg Loss :  0.11677965295634098 Train Loss :  0.16466856  Train accuracy :  0.9486859  Max accuracy :  0.9486859\n",
      "20 Avg Loss :  0.1071622861283166 Train Loss :  0.12498416  Train accuracy :  0.96370465  Max accuracy :  0.96370465\n",
      "30 Avg Loss :  0.10113675087424263 Train Loss :  0.14092189  Train accuracy :  0.9586984  Max accuracy :  0.96370465\n",
      "40 Avg Loss :  0.09414059572320964 Train Loss :  0.15090284  Train accuracy :  0.9612015  Max accuracy :  0.96370465\n",
      "50 Avg Loss :  0.08530998123543604 Train Loss :  0.1308585  Train accuracy :  0.96245307  Max accuracy :  0.96370465\n",
      "60 Avg Loss :  0.10376516862639357 Train Loss :  0.20059027  Train accuracy :  0.9586984  Max accuracy :  0.96370465\n",
      "70 Avg Loss :  0.08283126051537694 Train Loss :  0.18071824  Train accuracy :  0.95244056  Max accuracy :  0.96370465\n",
      "80 Avg Loss :  0.08471366982640965 Train Loss :  0.18587881  Train accuracy :  0.9499374  Max accuracy :  0.96370465\n",
      "90 Avg Loss :  0.09899920637586283 Train Loss :  0.22963732  Train accuracy :  0.95244056  Max accuracy :  0.96370465\n",
      "100 Avg Loss :  0.08038376403107707 Train Loss :  0.20553555  Train accuracy :  0.95619524  Max accuracy :  0.96370465\n",
      "110 Avg Loss :  0.06977210075794055 Train Loss :  0.27283627  Train accuracy :  0.9586984  Max accuracy :  0.96370465\n",
      "120 Avg Loss :  0.09242601170470674 Train Loss :  0.21275793  Train accuracy :  0.9574468  Max accuracy :  0.96370465\n",
      "130 Avg Loss :  0.08109870288587571 Train Loss :  0.23718223  Train accuracy :  0.95369214  Max accuracy :  0.96370465\n",
      "140 Avg Loss :  0.08408521315348999 Train Loss :  0.24149217  Train accuracy :  0.9612015  Max accuracy :  0.96370465\n",
      "150 Avg Loss :  0.0726100986524086 Train Loss :  0.19616725  Train accuracy :  0.9612015  Max accuracy :  0.96370465\n",
      "160 Avg Loss :  0.07671072942736956 Train Loss :  0.23162997  Train accuracy :  0.95494366  Max accuracy :  0.96370465\n",
      "170 Avg Loss :  0.09593960090673397 Train Loss :  0.18749219  Train accuracy :  0.9599499  Max accuracy :  0.96370465\n",
      "180 Avg Loss :  0.08972924921129431 Train Loss :  0.21878931  Train accuracy :  0.9574468  Max accuracy :  0.96370465\n",
      "190 Avg Loss :  0.0899429052369669 Train Loss :  0.18793328  Train accuracy :  0.95494366  Max accuracy :  0.96370465\n",
      "200 Avg Loss :  0.07333119893779179 Train Loss :  0.17878568  Train accuracy :  0.9586984  Max accuracy :  0.96370465\n",
      "210 Avg Loss :  0.07208742450789685 Train Loss :  0.20222189  Train accuracy :  0.9586984  Max accuracy :  0.96370465\n",
      "220 Avg Loss :  0.07954301437296504 Train Loss :  0.2766674  Train accuracy :  0.9586984  Max accuracy :  0.96370465\n",
      "230 Avg Loss :  0.08229172076763852 Train Loss :  0.32721084  Train accuracy :  0.9599499  Max accuracy :  0.96370465\n",
      "240 Avg Loss :  0.08476881855832678 Train Loss :  0.3311777  Train accuracy :  0.96370465  Max accuracy :  0.96370465\n",
      "250 Avg Loss :  0.07827930824298943 Train Loss :  0.21553804  Train accuracy :  0.9612015  Max accuracy :  0.96370465\n",
      "260 Avg Loss :  0.07401395542547107 Train Loss :  0.3443851  Train accuracy :  0.9599499  Max accuracy :  0.96370465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270 Avg Loss :  0.08403922401235571 Train Loss :  0.20382899  Train accuracy :  0.9612015  Max accuracy :  0.96370465\n",
      "280 Avg Loss :  0.08758503095512943 Train Loss :  0.14616257  Train accuracy :  0.95244056  Max accuracy :  0.96370465\n",
      "290 Avg Loss :  0.07026501804856321 Train Loss :  0.20100185  Train accuracy :  0.96245307  Max accuracy :  0.96370465\n",
      "300 Avg Loss :  0.06049767284587558 Train Loss :  0.18085665  Train accuracy :  0.9687109  Max accuracy :  0.9687109\n",
      "310 Avg Loss :  0.06361868192574807 Train Loss :  0.21720403  Train accuracy :  0.9586984  Max accuracy :  0.9687109\n",
      "320 Avg Loss :  0.0703664232610858 Train Loss :  0.2575721  Train accuracy :  0.9649562  Max accuracy :  0.9687109\n",
      "330 Avg Loss :  0.08189619221125861 Train Loss :  0.24998696  Train accuracy :  0.9586984  Max accuracy :  0.9687109\n",
      "340 Avg Loss :  0.08257252114292767 Train Loss :  0.30079213  Train accuracy :  0.96370465  Max accuracy :  0.9687109\n",
      "350 Avg Loss :  0.09006472354355666 Train Loss :  0.20414835  Train accuracy :  0.96370465  Max accuracy :  0.9687109\n",
      "360 Avg Loss :  0.06198123054179762 Train Loss :  0.250096  Train accuracy :  0.9574468  Max accuracy :  0.9687109\n",
      "370 Avg Loss :  0.14609904956471714 Train Loss :  0.2518869  Train accuracy :  0.9649562  Max accuracy :  0.9687109\n",
      "380 Avg Loss :  0.07529249032294114 Train Loss :  0.21646783  Train accuracy :  0.9699625  Max accuracy :  0.9699625\n",
      "390 Avg Loss :  0.06408213602844627 Train Loss :  0.23372954  Train accuracy :  0.9649562  Max accuracy :  0.9699625\n",
      "400 Avg Loss :  0.07953768798948403 Train Loss :  0.37254056  Train accuracy :  0.9649562  Max accuracy :  0.9699625\n",
      "410 Avg Loss :  0.06469162380588907 Train Loss :  0.16285448  Train accuracy :  0.9649562  Max accuracy :  0.9699625\n",
      "420 Avg Loss :  0.1744644274669034 Train Loss :  0.24863376  Train accuracy :  0.96620774  Max accuracy :  0.9699625\n",
      "430 Avg Loss :  0.12747934497227625 Train Loss :  0.32054454  Train accuracy :  0.9649562  Max accuracy :  0.9699625\n",
      "440 Avg Loss :  0.07749738118478233 Train Loss :  0.2086356  Train accuracy :  0.95369214  Max accuracy :  0.9699625\n",
      "450 Avg Loss :  0.07759864152675228 Train Loss :  0.19270775  Train accuracy :  0.9612015  Max accuracy :  0.9699625\n",
      "460 Avg Loss :  0.07327815328192495 Train Loss :  0.23454903  Train accuracy :  0.9674593  Max accuracy :  0.9699625\n",
      "470 Avg Loss :  0.08643171733378302 Train Loss :  0.4356315  Train accuracy :  0.9612015  Max accuracy :  0.9699625\n",
      "480 Avg Loss :  0.10221256881154007 Train Loss :  0.2411805  Train accuracy :  0.96245307  Max accuracy :  0.9699625\n",
      "490 Avg Loss :  0.08566652920230158 Train Loss :  0.31968442  Train accuracy :  0.9599499  Max accuracy :  0.9699625\n",
      "500 Avg Loss :  0.07732453228839274 Train Loss :  0.27864578  Train accuracy :  0.96620774  Max accuracy :  0.9699625\n",
      "510 Avg Loss :  0.10191563872753509 Train Loss :  0.33497256  Train accuracy :  0.96620774  Max accuracy :  0.9699625\n",
      "520 Avg Loss :  0.12726679337876184 Train Loss :  0.26358077  Train accuracy :  0.9699625  Max accuracy :  0.9699625\n",
      "530 Avg Loss :  0.11315265391853503 Train Loss :  0.2733187  Train accuracy :  0.9687109  Max accuracy :  0.9699625\n",
      "540 Avg Loss :  0.12399944696309312 Train Loss :  0.24827248  Train accuracy :  0.96620774  Max accuracy :  0.9699625\n",
      "550 Avg Loss :  0.07424611051101239 Train Loss :  0.28933486  Train accuracy :  0.9687109  Max accuracy :  0.9699625\n",
      "560 Avg Loss :  0.11069051281083374 Train Loss :  0.21625727  Train accuracy :  0.96620774  Max accuracy :  0.9699625\n",
      "570 Avg Loss :  0.0941354996258659 Train Loss :  0.27289104  Train accuracy :  0.96620774  Max accuracy :  0.9699625\n",
      "580 Avg Loss :  0.05809776406801704 Train Loss :  0.2870406  Train accuracy :  0.9674593  Max accuracy :  0.9699625\n",
      "590 Avg Loss :  0.11527821518081639 Train Loss :  0.37159052  Train accuracy :  0.9724656  Max accuracy :  0.9724656\n",
      "600 Avg Loss :  0.12210040596047683 Train Loss :  0.48591498  Train accuracy :  0.9612015  Max accuracy :  0.9724656\n",
      "610 Avg Loss :  0.07163773561894361 Train Loss :  0.38643813  Train accuracy :  0.9649562  Max accuracy :  0.9724656\n",
      "620 Avg Loss :  0.07622815342620015 Train Loss :  0.552604  Train accuracy :  0.96370465  Max accuracy :  0.9724656\n",
      "630 Avg Loss :  0.07169798267672639 Train Loss :  0.42405355  Train accuracy :  0.9649562  Max accuracy :  0.9724656\n",
      "640 Avg Loss :  0.10290533638492762 Train Loss :  0.22579977  Train accuracy :  0.95494366  Max accuracy :  0.9724656\n",
      "650 Avg Loss :  0.08333935239352287 Train Loss :  0.5851422  Train accuracy :  0.96245307  Max accuracy :  0.9724656\n",
      "660 Avg Loss :  0.07172809609411553 Train Loss :  0.35057235  Train accuracy :  0.9687109  Max accuracy :  0.9724656\n",
      "670 Avg Loss :  0.08379759390040169 Train Loss :  1.0096292  Train accuracy :  0.9687109  Max accuracy :  0.9724656\n",
      "680 Avg Loss :  0.08558983503774341 Train Loss :  0.33555058  Train accuracy :  0.9674593  Max accuracy :  0.9724656\n",
      "690 Avg Loss :  0.09573394963185172 Train Loss :  0.47820973  Train accuracy :  0.9674593  Max accuracy :  0.9724656\n",
      "700 Avg Loss :  0.1168257851053828 Train Loss :  1.1113877  Train accuracy :  0.96370465  Max accuracy :  0.9724656\n",
      "710 Avg Loss :  0.07858125625976495 Train Loss :  0.36952075  Train accuracy :  0.971214  Max accuracy :  0.9724656\n",
      "720 Avg Loss :  0.0881897384201043 Train Loss :  0.24906962  Train accuracy :  0.971214  Max accuracy :  0.9724656\n",
      "730 Avg Loss :  0.06387175380950792 Train Loss :  0.51033074  Train accuracy :  0.9674593  Max accuracy :  0.9724656\n",
      "740 Avg Loss :  0.07189910569494325 Train Loss :  0.56150776  Train accuracy :  0.9687109  Max accuracy :  0.9724656\n",
      "750 Avg Loss :  0.07619547137125796 Train Loss :  0.58704805  Train accuracy :  0.9687109  Max accuracy :  0.9724656\n",
      "760 Avg Loss :  0.08500678373301136 Train Loss :  0.39133352  Train accuracy :  0.96370465  Max accuracy :  0.9724656\n",
      "770 Avg Loss :  0.09142732269330213 Train Loss :  0.46034423  Train accuracy :  0.9699625  Max accuracy :  0.9724656\n",
      "780 Avg Loss :  0.07661640012104597 Train Loss :  0.2132152  Train accuracy :  0.9699625  Max accuracy :  0.9724656\n",
      "790 Avg Loss :  0.08803237795031497 Train Loss :  0.19842482  Train accuracy :  0.971214  Max accuracy :  0.9724656\n",
      "800 Avg Loss :  0.1288210432643869 Train Loss :  0.5939105  Train accuracy :  0.9687109  Max accuracy :  0.9724656\n",
      "810 Avg Loss :  0.15426125552039593 Train Loss :  0.32165527  Train accuracy :  0.96245307  Max accuracy :  0.9724656\n",
      "820 Avg Loss :  0.07055794076794492 Train Loss :  0.36647126  Train accuracy :  0.9699625  Max accuracy :  0.9724656\n",
      "830 Avg Loss :  0.0629352147058983 Train Loss :  0.5322337  Train accuracy :  0.96245307  Max accuracy :  0.9724656\n",
      "840 Avg Loss :  0.09384725911409728 Train Loss :  0.500986  Train accuracy :  0.96245307  Max accuracy :  0.9724656\n",
      "850 Avg Loss :  0.08833307214081289 Train Loss :  0.7548019  Train accuracy :  0.96370465  Max accuracy :  0.9724656\n",
      "860 Avg Loss :  0.07914684323727023 Train Loss :  0.26856017  Train accuracy :  0.9687109  Max accuracy :  0.9724656\n",
      "870 Avg Loss :  0.11260586093911637 Train Loss :  0.61631906  Train accuracy :  0.96620774  Max accuracy :  0.9724656\n",
      "880 Avg Loss :  0.07969351245888642 Train Loss :  0.5586483  Train accuracy :  0.971214  Max accuracy :  0.9724656\n",
      "890 Avg Loss :  0.05519424919371627 Train Loss :  0.46698162  Train accuracy :  0.9699625  Max accuracy :  0.9724656\n",
      "900 Avg Loss :  0.1057974684018908 Train Loss :  0.6382512  Train accuracy :  0.96245307  Max accuracy :  0.9724656\n",
      "910 Avg Loss :  0.10821051476523282 Train Loss :  0.6053549  Train accuracy :  0.9612015  Max accuracy :  0.9724656\n",
      "920 Avg Loss :  0.1421203652030921 Train Loss :  1.1401758  Train accuracy :  0.9612015  Max accuracy :  0.9724656\n",
      "930 Avg Loss :  0.08538877621426114 Train Loss :  0.64758354  Train accuracy :  0.971214  Max accuracy :  0.9724656\n",
      "940 Avg Loss :  0.12461514182255737 Train Loss :  0.44997263  Train accuracy :  0.97622025  Max accuracy :  0.97622025\n",
      "950 Avg Loss :  0.07331473962403834 Train Loss :  0.37775704  Train accuracy :  0.96245307  Max accuracy :  0.97622025\n",
      "960 Avg Loss :  0.07670927071012558 Train Loss :  0.91805583  Train accuracy :  0.96620774  Max accuracy :  0.97622025\n",
      "970 Avg Loss :  0.07517306569830648 Train Loss :  0.37010172  Train accuracy :  0.96620774  Max accuracy :  0.97622025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980 Avg Loss :  0.08359992913236576 Train Loss :  0.7326379  Train accuracy :  0.96245307  Max accuracy :  0.97622025\n",
      "990 Avg Loss :  0.05815113996089039 Train Loss :  0.49652672  Train accuracy :  0.9649562  Max accuracy :  0.97622025\n",
      "INFO:tensorflow:Restoring parameters from ./mymodel_final.ckpt\n",
      "DNN result\n",
      "[[515  11]\n",
      " [ 16 257]]\n",
      "0.9662077596996246\n",
      "XGB result\n",
      "[[507  19]\n",
      " [  9 264]]\n",
      "0.9649561952440551\n",
      "RF result\n",
      "[[512  14]\n",
      " [ 11 262]]\n",
      "0.9687108886107635\n",
      "SVM result\n",
      "[[510  16]\n",
      " [ 15 258]]\n",
      "0.9612015018773467\n",
      "EN result\n",
      "[[508  18]\n",
      " [  7 266]]\n",
      "0.9687108886107635\n",
      "XGB 평균 정확도 :  0.9612393511552362\n",
      "RF 평균 정확도 :  0.9641154478366373\n",
      "SVM 평균 정확도 :  0.9624890394359991\n",
      "DNN 평균 정확도 :  0.9539891927565514\n",
      "앙상블 평균 정확도 :  0.9652407595558742\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#sklearn 라이브러리를 사용하여 학습데이터를 학습/테스트 데이터로 나눔 (10-Fold)\n",
    "#악성앱과 정상앱이 2:1비율이므로 학습데이터 편향을 막기위해 Stratified K Fold를 사용\n",
    "cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42) #Seed고정\n",
    "cv.get_n_splits(X, y)\n",
    "\n",
    "average_accuracy_XGB=0\n",
    "average_accuracy_RF=0\n",
    "average_accuracy_SVM=0\n",
    "average_accuracy_DNN=0\n",
    "average_accuracy_EN=0\n",
    "\n",
    "#10-Fold한 학습/테스트 추출\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    X_train, X_test=X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test=y.iloc[train_index], y.iloc[test_index]\n",
    "    #데이터구조 확인 (5398,) (600,), 마지막 2개 데이터셋은 각각 (5399,) (599,)\n",
    "    #print(X_train.shape, X_test.shape) \n",
    "    \n",
    "    #악성:정상 2:1로 나뉘었는지 확인\n",
    "    #print(X_train[X_train['label']==0].shape, X_train[X_train['label']==1].shape, X_test[X_test['label']==0].shape, X_test[X_test['label']==1].shape)\n",
    "    \n",
    "    y_pred_DNN=do_DNN(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    cnf_matrix_DNN = confusion_matrix(y_test, y_pred_DNN)\n",
    "    accuracy_DNN = accuracy_score(y_test, y_pred_DNN)\n",
    "    average_accuracy_DNN+=accuracy_DNN\n",
    "    \n",
    "    print(\"DNN result\")\n",
    "    print(cnf_matrix_DNN)\n",
    "    print(accuracy_DNN)\n",
    "    \n",
    "    y_pred_XGB=do_XGBClassifier(X_train, y_train, X_test)\n",
    "    \n",
    "    cnf_matrix_XGB = confusion_matrix(y_test, y_pred_XGB)\n",
    "    accuracy_XGB = accuracy_score(y_test, y_pred_XGB)\n",
    "    average_accuracy_XGB+=accuracy_XGB\n",
    "    \n",
    "    print(\"XGB result\")\n",
    "    print(cnf_matrix_XGB)\n",
    "    print(accuracy_XGB)\n",
    "    \n",
    "    y_pred_RF=do_Rf(X_train, y_train, X_test, ESTIMATOR=200)\n",
    "    \n",
    "    cnf_matrix_RF = confusion_matrix(y_test, y_pred_RF)\n",
    "    accuracy_RF = accuracy_score(y_test, y_pred_RF)\n",
    "    average_accuracy_RF+=accuracy_RF\n",
    "    \n",
    "    print(\"RF result\")\n",
    "    print(cnf_matrix_RF)\n",
    "    print(accuracy_RF)\n",
    "    \n",
    "    y_pred_SVM=do_SVM(X_train, y_train, X_test, 1000, 0.001)\n",
    "    \n",
    "    cnf_matrix_SVM = confusion_matrix(y_test, y_pred_SVM)\n",
    "    accuracy_SVM = accuracy_score(y_test, y_pred_SVM)\n",
    "    average_accuracy_SVM+=accuracy_SVM\n",
    "    \n",
    "    print(\"SVM result\")\n",
    "    print(cnf_matrix_SVM)\n",
    "    print(accuracy_SVM)\n",
    "    \n",
    "    df=pd.DataFrame([y_pred_DNN,y_pred_RF,y_pred_SVM,y_pred_XGB], index=['DNN', 'RF', 'SVM', 'XGB'])\n",
    "    df=df.transpose()\n",
    "    \n",
    "    df['EN']=df.apply(lambda x: 1 if (x['DNN']+x['RF']+x['SVM']+x['XGB'])/4>=0.5 else 0, axis=1)\n",
    "    y_pred_EN=df['EN']\n",
    "    \n",
    "    cnf_matrix_EN = confusion_matrix(y_test, y_pred_EN)\n",
    "    accuracy_EN = accuracy_score(y_test, y_pred_EN)\n",
    "    average_accuracy_EN+=accuracy_EN\n",
    "    \n",
    "    print(\"EN result\")\n",
    "    print(cnf_matrix_EN)\n",
    "    print(accuracy_EN)\n",
    "    \n",
    "print(\"XGB 평균 정확도 : \", average_accuracy_XGB/10)\n",
    "print(\"RF 평균 정확도 : \", average_accuracy_RF/10)\n",
    "print(\"SVM 평균 정확도 : \", average_accuracy_SVM/10)\n",
    "print(\"DNN 평균 정확도 : \", average_accuracy_DNN/10)\n",
    "print(\"앙상블 평균 정확도 : \", average_accuracy_EN/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1933419b400>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = pyplot.subplots(figsize=(10,10))         \n",
    "sns.heatmap(df.corr(), annot=True, linewidth=.5, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Avg Loss :  0.29042202306370574 Train Loss :  0.12592341  Train accuracy :  0.951189  Max accuracy :  0.951189\n",
      "10 Avg Loss :  0.11789486971834018 Train Loss :  0.08046331  Train accuracy :  0.9674593  Max accuracy :  0.9674593\n",
      "20 Avg Loss :  0.10438614134346287 Train Loss :  0.06287901  Train accuracy :  0.9787234  Max accuracy :  0.9787234\n",
      "30 Avg Loss :  0.11084171739076416 Train Loss :  0.0710046  Train accuracy :  0.9699625  Max accuracy :  0.9787234\n",
      "40 Avg Loss :  0.08247653271762596 Train Loss :  0.053757984  Train accuracy :  0.9824781  Max accuracy :  0.9824781\n",
      "50 Avg Loss :  0.0963975676004925 Train Loss :  0.06232254  Train accuracy :  0.9812265  Max accuracy :  0.9824781\n",
      "60 Avg Loss :  0.09702918459210667 Train Loss :  0.045499977  Train accuracy :  0.98372966  Max accuracy :  0.98372966\n",
      "70 Avg Loss :  0.08531292050235693 Train Loss :  0.046533745  Train accuracy :  0.9862328  Max accuracy :  0.9862328\n",
      "80 Avg Loss :  0.08583462160200844 Train Loss :  0.046674155  Train accuracy :  0.979975  Max accuracy :  0.9862328\n",
      "90 Avg Loss :  0.08731848968853871 Train Loss :  0.029754158  Train accuracy :  0.9887359  Max accuracy :  0.9887359\n",
      "100 Avg Loss :  0.08127021782040114 Train Loss :  0.026313448  Train accuracy :  0.9924906  Max accuracy :  0.9924906\n",
      "110 Avg Loss :  0.0629337828966879 Train Loss :  0.035578113  Train accuracy :  0.9887359  Max accuracy :  0.9924906\n",
      "120 Avg Loss :  0.07405767068567293 Train Loss :  0.027775906  Train accuracy :  0.99374217  Max accuracy :  0.99374217\n",
      "130 Avg Loss :  0.1002672982191847 Train Loss :  0.03688245  Train accuracy :  0.9899875  Max accuracy :  0.99374217\n",
      "140 Avg Loss :  0.08064443050252816 Train Loss :  0.029071791  Train accuracy :  0.9924906  Max accuracy :  0.99374217\n",
      "150 Avg Loss :  0.06556965352126186 Train Loss :  0.030523537  Train accuracy :  0.99374217  Max accuracy :  0.99374217\n",
      "160 Avg Loss :  0.08622317093484583 Train Loss :  0.028358836  Train accuracy :  0.99499375  Max accuracy :  0.99499375\n",
      "170 Avg Loss :  0.07564159359542592 Train Loss :  0.030361226  Train accuracy :  0.99499375  Max accuracy :  0.99499375\n",
      "180 Avg Loss :  0.07658300828188656 Train Loss :  0.016651867  Train accuracy :  0.9962453  Max accuracy :  0.9962453\n",
      "190 Avg Loss :  0.06435159195004213 Train Loss :  0.016972305  Train accuracy :  0.9962453  Max accuracy :  0.9962453\n",
      "200 Avg Loss :  0.081870220932028 Train Loss :  0.032159105  Train accuracy :  0.99374217  Max accuracy :  0.9962453\n",
      "210 Avg Loss :  0.12072241802008883 Train Loss :  0.046464894  Train accuracy :  0.9862328  Max accuracy :  0.9962453\n",
      "220 Avg Loss :  0.10058054802638866 Train Loss :  0.04186568  Train accuracy :  0.98748434  Max accuracy :  0.9962453\n",
      "230 Avg Loss :  0.07684998736987192 Train Loss :  0.019553345  Train accuracy :  0.99374217  Max accuracy :  0.9962453\n",
      "240 Avg Loss :  0.08280706716581218 Train Loss :  0.017225565  Train accuracy :  0.99374217  Max accuracy :  0.9962453\n",
      "250 Avg Loss :  0.08677967325333626 Train Loss :  0.023565928  Train accuracy :  0.9899875  Max accuracy :  0.9962453\n",
      "260 Avg Loss :  0.07585937333022873 Train Loss :  0.0266863  Train accuracy :  0.99374217  Max accuracy :  0.9962453\n",
      "270 Avg Loss :  0.0902186574624671 Train Loss :  0.027201883  Train accuracy :  0.98748434  Max accuracy :  0.9962453\n",
      "280 Avg Loss :  0.06799004782712267 Train Loss :  0.015469035  Train accuracy :  0.99374217  Max accuracy :  0.9962453\n",
      "290 Avg Loss :  0.0750023243618348 Train Loss :  0.026604226  Train accuracy :  0.9912391  Max accuracy :  0.9962453\n",
      "300 Avg Loss :  0.1258674584809811 Train Loss :  0.016710933  Train accuracy :  0.99374217  Max accuracy :  0.9962453\n",
      "310 Avg Loss :  0.09040097156239131 Train Loss :  0.023877477  Train accuracy :  0.9912391  Max accuracy :  0.9962453\n",
      "320 Avg Loss :  0.06175485753544398 Train Loss :  0.019528031  Train accuracy :  0.9912391  Max accuracy :  0.9962453\n",
      "330 Avg Loss :  0.06996900170680977 Train Loss :  0.016498704  Train accuracy :  0.9924906  Max accuracy :  0.9962453\n",
      "340 Avg Loss :  0.07055226591746172 Train Loss :  0.019784626  Train accuracy :  0.99499375  Max accuracy :  0.9962453\n",
      "350 Avg Loss :  0.07086629160649836 Train Loss :  0.018925415  Train accuracy :  0.99374217  Max accuracy :  0.9962453\n",
      "360 Avg Loss :  0.07289131111916033 Train Loss :  0.01782676  Train accuracy :  0.9962453  Max accuracy :  0.9962453\n",
      "370 Avg Loss :  0.07334615879001155 Train Loss :  0.019017825  Train accuracy :  0.9899875  Max accuracy :  0.9962453\n",
      "380 Avg Loss :  0.12762505953170117 Train Loss :  0.021796757  Train accuracy :  0.9924906  Max accuracy :  0.9962453\n",
      "390 Avg Loss :  0.10624271781454164 Train Loss :  0.024294522  Train accuracy :  0.98748434  Max accuracy :  0.9962453\n",
      "400 Avg Loss :  0.08112429307713624 Train Loss :  0.021856263  Train accuracy :  0.9924906  Max accuracy :  0.9962453\n",
      "410 Avg Loss :  0.07038948142660723 Train Loss :  0.025830187  Train accuracy :  0.9887359  Max accuracy :  0.9962453\n",
      "420 Avg Loss :  0.06395121859086136 Train Loss :  0.009129544  Train accuracy :  0.99749684  Max accuracy :  0.99749684\n",
      "430 Avg Loss :  0.07750629705767477 Train Loss :  0.021793127  Train accuracy :  0.99374217  Max accuracy :  0.99749684\n",
      "440 Avg Loss :  0.07557593252990512 Train Loss :  0.037928477  Train accuracy :  0.98498124  Max accuracy :  0.99749684\n",
      "450 Avg Loss :  0.09797125039321762 Train Loss :  0.026786821  Train accuracy :  0.9924906  Max accuracy :  0.99749684\n",
      "460 Avg Loss :  0.08153184902884306 Train Loss :  0.025743669  Train accuracy :  0.99374217  Max accuracy :  0.99749684\n",
      "470 Avg Loss :  0.0919056019235042 Train Loss :  0.018249134  Train accuracy :  0.99499375  Max accuracy :  0.99749684\n",
      "480 Avg Loss :  0.09556335997917961 Train Loss :  0.044958025  Train accuracy :  0.99374217  Max accuracy :  0.99749684\n",
      "490 Avg Loss :  0.06325551383798161 Train Loss :  0.013162709  Train accuracy :  0.99499375  Max accuracy :  0.99749684\n",
      "500 Avg Loss :  0.06362394958494173 Train Loss :  0.026934957  Train accuracy :  0.99499375  Max accuracy :  0.99749684\n",
      "510 Avg Loss :  0.057563446642410365 Train Loss :  0.023136526  Train accuracy :  0.99374217  Max accuracy :  0.99749684\n",
      "520 Avg Loss :  0.05636565525445245 Train Loss :  0.014836331  Train accuracy :  0.99749684  Max accuracy :  0.99749684\n",
      "530 Avg Loss :  0.08726374830509867 Train Loss :  0.046178605  Train accuracy :  0.9862328  Max accuracy :  0.99749684\n",
      "540 Avg Loss :  0.12745437957346442 Train Loss :  0.029449834  Train accuracy :  0.99374217  Max accuracy :  0.99749684\n",
      "550 Avg Loss :  0.13767595817485165 Train Loss :  0.038338386  Train accuracy :  0.9912391  Max accuracy :  0.99749684\n",
      "560 Avg Loss :  0.07862354090978059 Train Loss :  0.045413375  Train accuracy :  0.98498124  Max accuracy :  0.99749684\n",
      "570 Avg Loss :  0.08841117922096484 Train Loss :  0.021003509  Train accuracy :  0.9962453  Max accuracy :  0.99749684\n",
      "580 Avg Loss :  0.07691091545406852 Train Loss :  0.03102309  Train accuracy :  0.9912391  Max accuracy :  0.99749684\n",
      "590 Avg Loss :  0.1527601814558429 Train Loss :  0.054005276  Train accuracy :  0.9912391  Max accuracy :  0.99749684\n",
      "600 Avg Loss :  0.10492303727134579 Train Loss :  0.036742005  Train accuracy :  0.9899875  Max accuracy :  0.99749684\n",
      "610 Avg Loss :  0.08934900197651116 Train Loss :  0.028581724  Train accuracy :  0.99374217  Max accuracy :  0.99749684\n",
      "620 Avg Loss :  0.1484149514186767 Train Loss :  0.044095505  Train accuracy :  0.96370465  Max accuracy :  0.99749684\n",
      "630 Avg Loss :  0.1188873433838448 Train Loss :  0.028795438  Train accuracy :  0.9924906  Max accuracy :  0.99749684\n",
      "640 Avg Loss :  0.13276053971100243 Train Loss :  0.023667935  Train accuracy :  0.9912391  Max accuracy :  0.99749684\n",
      "650 Avg Loss :  0.11221529957988569 Train Loss :  0.02953582  Train accuracy :  0.99374217  Max accuracy :  0.99749684\n",
      "660 Avg Loss :  0.08448154335060426 Train Loss :  0.03563471  Train accuracy :  0.9924906  Max accuracy :  0.99749684\n",
      "670 Avg Loss :  0.12384693240446429 Train Loss :  0.048200663  Train accuracy :  0.98748434  Max accuracy :  0.99749684\n",
      "680 Avg Loss :  0.18888170031770582 Train Loss :  0.119440794  Train accuracy :  0.9436796  Max accuracy :  0.99749684\n",
      "690 Avg Loss :  0.09031680151219328 Train Loss :  0.01954482  Train accuracy :  0.9912391  Max accuracy :  0.99749684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 Avg Loss :  0.10683870357611487 Train Loss :  0.023736516  Train accuracy :  0.9887359  Max accuracy :  0.99749684\n",
      "710 Avg Loss :  0.10107556192745126 Train Loss :  0.029829757  Train accuracy :  0.9924906  Max accuracy :  0.99749684\n",
      "720 Avg Loss :  0.07368331249322621 Train Loss :  0.037244014  Train accuracy :  0.9824781  Max accuracy :  0.99749684\n",
      "730 Avg Loss :  0.07748943456118144 Train Loss :  0.028007152  Train accuracy :  0.9862328  Max accuracy :  0.99749684\n",
      "740 Avg Loss :  0.09846813655308177 Train Loss :  0.030248601  Train accuracy :  0.99374217  Max accuracy :  0.99749684\n",
      "750 Avg Loss :  0.08111826787071845 Train Loss :  0.03535088  Train accuracy :  0.9899875  Max accuracy :  0.99749684\n",
      "760 Avg Loss :  0.15827918996012977 Train Loss :  0.076825045  Train accuracy :  0.95369214  Max accuracy :  0.99749684\n",
      "770 Avg Loss :  0.12180076160978887 Train Loss :  0.06133235  Train accuracy :  0.9862328  Max accuracy :  0.99749684\n",
      "780 Avg Loss :  0.08576450133395773 Train Loss :  0.038911045  Train accuracy :  0.99499375  Max accuracy :  0.99749684\n",
      "790 Avg Loss :  0.14476182945673507 Train Loss :  0.02603602  Train accuracy :  0.9924906  Max accuracy :  0.99749684\n",
      "800 Avg Loss :  0.10823853812631097 Train Loss :  0.02240867  Train accuracy :  0.9887359  Max accuracy :  0.99749684\n",
      "810 Avg Loss :  0.07598301347705626 Train Loss :  0.023965325  Train accuracy :  0.99749684  Max accuracy :  0.99749684\n",
      "820 Avg Loss :  0.07534570344573548 Train Loss :  0.016646158  Train accuracy :  0.98748434  Max accuracy :  0.99749684\n",
      "830 Avg Loss :  0.07916919108960899 Train Loss :  0.02466495  Train accuracy :  0.98748434  Max accuracy :  0.99749684\n",
      "840 Avg Loss :  0.07667064161280229 Train Loss :  0.018113546  Train accuracy :  0.9924906  Max accuracy :  0.99749684\n",
      "850 Avg Loss :  0.0811427363284653 Train Loss :  0.029241657  Train accuracy :  0.99499375  Max accuracy :  0.99749684\n",
      "860 Avg Loss :  0.08907575148247905 Train Loss :  0.019304788  Train accuracy :  0.9924906  Max accuracy :  0.99749684\n",
      "870 Avg Loss :  0.06867111023635634 Train Loss :  0.029381704  Train accuracy :  0.9924906  Max accuracy :  0.99749684\n",
      "880 Avg Loss :  0.11096683297786986 Train Loss :  0.044471864  Train accuracy :  0.9687109  Max accuracy :  0.99749684\n",
      "890 Avg Loss :  0.13942678122510835 Train Loss :  0.080883086  Train accuracy :  0.97622025  Max accuracy :  0.99749684\n",
      "900 Avg Loss :  0.1186338841855045 Train Loss :  0.037550945  Train accuracy :  0.99374217  Max accuracy :  0.99749684\n",
      "910 Avg Loss :  0.104046058720879 Train Loss :  0.041856  Train accuracy :  0.9862328  Max accuracy :  0.99749684\n",
      "920 Avg Loss :  0.09339643247245304 Train Loss :  0.034274932  Train accuracy :  0.99499375  Max accuracy :  0.99749684\n",
      "930 Avg Loss :  0.09104604886904835 Train Loss :  0.028434964  Train accuracy :  0.99499375  Max accuracy :  0.99749684\n",
      "940 Avg Loss :  0.09101321039000343 Train Loss :  0.030537643  Train accuracy :  0.99374217  Max accuracy :  0.99749684\n",
      "950 Avg Loss :  0.12922493895635973 Train Loss :  0.019341456  Train accuracy :  0.99749684  Max accuracy :  0.99749684\n",
      "960 Avg Loss :  0.07767041625394937 Train Loss :  0.016132005  Train accuracy :  0.9987484  Max accuracy :  0.9987484\n",
      "970 Avg Loss :  0.1705031987099397 Train Loss :  0.016441256  Train accuracy :  0.99749684  Max accuracy :  0.9987484\n",
      "980 Avg Loss :  0.10964269512483192 Train Loss :  0.025308777  Train accuracy :  0.99749684  Max accuracy :  0.9987484\n",
      "990 Avg Loss :  0.10033589805806839 Train Loss :  0.036608845  Train accuracy :  0.9912391  Max accuracy :  0.9987484\n",
      "INFO:tensorflow:Restoring parameters from ./mymodel_final.ckpt\n",
      "EN result\n",
      "[[524   2]\n",
      " [  0 273]]\n",
      "0.9974968710888611\n",
      "최종 앙상블 정확도 :  0.9974968710888611\n"
     ]
    }
   ],
   "source": [
    "y_pred_DNN=do_DNN(X, y, X_test, y_test)\n",
    "y_pred_XGB=do_XGBClassifier(X, y, X_test)\n",
    "y_pred_RF=do_Rf(X, y, X_test, ESTIMATOR=200)\n",
    "y_pred_SVM=do_SVM(X, y, X_test, 1000, 0.001)\n",
    "    \n",
    "df=pd.DataFrame([y_pred_DNN,y_pred_RF,y_pred_SVM,y_pred_XGB], index=['DNN', 'RF', 'SVM', 'XGB'])\n",
    "df=df.transpose()\n",
    "    \n",
    "df['EN']=df.apply(lambda x: 1 if (x['DNN']+x['RF']+x['SVM']+x['XGB'])/4>=0.5 else 0, axis=1)\n",
    "y_pred_EN=df['EN']\n",
    "    \n",
    "cnf_matrix_EN = confusion_matrix(y_test, y_pred_EN)\n",
    "accuracy_EN = accuracy_score(y_test, y_pred_EN)\n",
    "    \n",
    "print(\"EN result\")\n",
    "print(cnf_matrix_EN)\n",
    "print(accuracy_EN)\n",
    "    \n",
    "print(\"최종 앙상블 정확도 : \",accuracy_EN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
