{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5261, 141) (2737, 141) (1978, 141)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#피쳐로 추출한 테스트데이터 불러오기\n",
    "#with_suspicious_perm.csv : 악성코드에서 자주 사용되는 권한만 사용\n",
    "#악성앱과 정상앱 각각 불러오기\n",
    "normal_path='./extract-from-apk-master/out/0-normal/with_suspicious_perm.csv'\n",
    "malware_path='./extract-from-apk-master/out/1-malware/with_suspicious_perm.csv'\n",
    "test_path='./extract-from-apk-master/out/test/with_suspicious_perm.csv'\n",
    "\n",
    "#csv로 읽기\n",
    "normal_data=pd.read_csv(normal_path)\n",
    "malware_data=pd.read_csv(malware_path)\n",
    "test_data=pd.read_csv(test_path)\n",
    "\n",
    "#데이터 구조 확인\n",
    "#normal_data : (4000, 141)\n",
    "#malware_data : (1988,141)  2개는 dex파일 에러로 피쳐추출 실패\n",
    "print(normal_data.shape, malware_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7998, 141)\n"
     ]
    }
   ],
   "source": [
    "#악성, 정상앱 학습데이터 병합\n",
    "data=pd.concat([normal_data, malware_data])\n",
    "\n",
    "#데이터 구조 확인\n",
    "#(5998,141)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1978, 115)\n"
     ]
    }
   ],
   "source": [
    "#의미없는 피쳐 제거\n",
    "test_data=test_data.iloc[:,(data.max()!=data.min()).tolist()[:-1]]\n",
    "\n",
    "#데이터 구조 확인\n",
    "#(5998, 112)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['size']=(test_data['size']-np.mean(data['size']))/np.std(data['size'])\n",
    "test_data['ep']=(test_data['ep']-np.mean(data['ep']))/np.std(data['ep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "def check(x_test):\n",
    "    \n",
    "    model_XGB=joblib.load('./XGB_model.pkl')\n",
    "    y_pred_XGB = model_XGB.predict(x_test)\n",
    "    \n",
    "    model_RF=joblib.load('./RF_model.pkl')\n",
    "    y_pred_RF = model_RF.predict(x_test)\n",
    "    \n",
    "    model_SVM=joblib.load('./SVM_model.pkl')\n",
    "    y_pred_SVM = model_SVM.predict(x_test)\n",
    "    \n",
    "    \n",
    "    #parameters\n",
    "    n_inputs=114 #suspiciou = 135 full=229\n",
    "    n_hidden1=200\n",
    "    n_hidden2=200\n",
    "    n_outputs=2\n",
    "\n",
    "    scale1=0.001\n",
    "    scale2=0.001\n",
    "\n",
    "    dropout_rate=0.1 # == 1 - keep_prob\n",
    "\n",
    "    learning_rate=0.03\n",
    "\n",
    "    n_epochs = 1000\n",
    "    display_step=10\n",
    "    batch_size = 128\n",
    "    batch_num=5998//batch_size\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    X=tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "    Y=tf.placeholder(tf.int64, shape=(None), name=\"Y\")\n",
    "\n",
    "    training=tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "    with tf.name_scope(\"dnn\"):\n",
    "        X_drop=tf.layers.dropout(X, dropout_rate, training=training)\n",
    "        hidden1 = tf.layers.dense(X_drop, n_hidden1, name=\"hidden1\", activation=tf.nn.relu, kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(scale1, scale2))\n",
    "        hidden1_dropp=tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "        hidden2 = tf.layers.dense(hidden1_dropp, n_hidden2, name=\"hidden2\", activation=tf.nn.relu, kernel_regularizer=tf.contrib.layers.l1_l2_regularizer(scale1, scale2))\n",
    "        hidden2_dropp=tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "        logits = tf.layers.dense(hidden2_dropp, n_outputs, name=\"outputs\")\n",
    "    \n",
    "    with tf.name_scope(\"loss\"):\n",
    "        xentropy=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y, logits=logits)\n",
    "        loss=tf.reduce_mean(xentropy, name=\"loss\")\n",
    "        loss_summary = tf.summary.scalar('loss',loss)\n",
    "    \n",
    "    with tf.name_scope(\"train\"):\n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "    \n",
    "    with tf.name_scope(\"eval\"):\n",
    "        correct = tf.nn.in_top_k(logits, Y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        accuracy_summary = tf.summary.scalar('accuracy',accuracy)\n",
    "    \n",
    "    merged = tf.summary.merge_all()\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, \"./mymodel_final.ckpt\")\n",
    "        Z=logits.eval(feed_dict={X:x_test})\n",
    "        y_pred_DNN=np.argmax(Z, axis=1)\n",
    "        \n",
    "        \n",
    "    df=pd.DataFrame([y_pred_DNN,y_pred_RF,y_pred_SVM,y_pred_XGB], index=['DNN', 'RF', 'SVM', 'XGB'])\n",
    "    df=df.transpose()\n",
    "    df['EN']=df.apply(lambda x: 1 if (x['DNN']+x['RF']+x['SVM']+x['XGB'])/4>=0.5 else 0, axis=1)\n",
    "    y_pred_EN=df['EN']\n",
    "    \n",
    "    return y_pred_EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mymodel_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "test_data['pred']=check(test_data.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.iloc[:,[0,-1]].to_csv('out.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
