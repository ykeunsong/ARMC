{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 137) (1998, 137) (4000, 136)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "import tensorflow as tf\n",
    "\n",
    "#피쳐로 추출한 테스트데이터 불러오기\n",
    "#with_suspicious_perm.csv : 악성코드에서 자주 사용되는 권한만 사용\n",
    "#악성앱과 정상앱 각각 불러오기\n",
    "normal_path='./extract-from-apk-master/out/0-normal/with_suspicious_perm.csv'\n",
    "malware_path='./extract-from-apk-master/out/1-malware/with_suspicious_perm.csv'\n",
    "test_path='./extract-from-apk-master/out/test/with_suspicious_perm.csv'\n",
    "\n",
    "#csv로 읽기\n",
    "normal_data=pd.read_csv(normal_path)\n",
    "malware_data=pd.read_csv(malware_path)\n",
    "test_data=pd.read_csv(test_path)\n",
    "\n",
    "#데이터 구조 확인\n",
    "#normal_data : (4000, 137)\n",
    "#malware_data : (1988,137)  2개는 dex파일 에러로 피쳐추출 실패\n",
    "print(normal_data.shape, malware_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5998, 137)\n"
     ]
    }
   ],
   "source": [
    "#악성, 정상앱 학습데이터 병합\n",
    "data=pd.concat([normal_data, malware_data])\n",
    "\n",
    "#데이터 구조 확인\n",
    "#(5998,137)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 111)\n"
     ]
    }
   ],
   "source": [
    "#의미없는 피쳐 제거\n",
    "test_data=test_data.iloc[:,(data.max()!=data.min()).tolist()[:-1]]\n",
    "\n",
    "#데이터 구조 확인\n",
    "#(5998, 112)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "def check(x_test):\n",
    "    \n",
    "    model_XGB=joblib.load('./XGB_model.pkl')\n",
    "    y_pred_XGB = model_XGB.predict(x_test)\n",
    "    \n",
    "    model_RF=joblib.load('./RF_model.pkl')\n",
    "    y_pred_RF = model_RF.predict(x_test)\n",
    "    \n",
    "    model_SVM=joblib.load('./SVM_model.pkl')\n",
    "    y_pred_SVM = model_SVM.predict(x_test)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    loader = tf.train.import_meta_graph('./mymodel_final.ckpt.meta')\n",
    "    with tf.Session() as sess:\n",
    "        loader.restore(sess, \"./mymodel_final.ckpt\")\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        logits = tf.get_default_graph().get_tensor_by_name(\"outputs:0\")\n",
    "        \n",
    "        Z=logits.eval(feed_dict={X:x_test})\n",
    "        y_pred_DNN=np.argmax(Z, axis=1)\n",
    "        \n",
    "    df=pd.DataFrame([y_pred_DNN,y_pred_RF,y_pred_SVM,y_pred_XGB], index=['DNN', 'RF', 'SVM', 'XGB'])\n",
    "    df=df.transpose()\n",
    "    df['EN']=df.apply(lambda x: 1 if (x['DNN']+x['RF']+x['SVM']+x['XGB'])/4>=0.5 else 0, axis=1)\n",
    "    y_pred_EN=df['EN']\n",
    "    \n",
    "    return y_pred_EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['pred']=check(test_data.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('out.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
